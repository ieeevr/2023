id,title,authors,abstract,url,hall,booth
PO1016,Boarding Sensation Presentation of the Biped Walking Robot with a Low-cost Two-axis Motion Platform,Kyosuke Mori: Hiroshima City University; Wataru Wakita: Hiroshima City University,"We render a boarding sensation of a biped robot at low cost and high immersive by approximate the 6-DOF motion such as the impact, vibration, and steep slope experienced on boarding a biped robot to a 2-DOF rolling motion at max ± 25 degrees in both at pitch and roll directions with our low-cost two-axis motion platform.",https://youtu.be/oQlC2pOd7SM,Expo Hall B,C23
PO1017,Virtual Equipment System: Face Mask and Voodoo Doll for User Privacy and Self-Expression Options in Virtual Reality,Powen Yao: University of Southern California; Vangelis Lympouridis: USC; Michael Zyda: USC,"Current trends in immersive technologies suggest an increase in capturing user’s data to drive interactions and avatar representations. With growing numbers of data types being collected, users need an easy way to view and control their privacy settings. In this demo, we present a method for users to adjust options related to privacy settings, user data collection, and self-expression through the use of 3D user interface metaphors such as a mask and a voodoo doll.",https://www.youtube.com/watch?v=RazSyF9W1nU&t=3s,Expo Hall A,C26
PO1019,Demonstrating High-Precision and High-Fidelity Digital Inking for Virtual Reality,Hugo Romat: ETH Zurich; Andreas Rene Fender: ETH; Manuel Meier: ETH Zürich; Christian Holz: ETH Zürich,"Digital pen interaction has become a first-class input modality for precision tasks such as writing, annotating, and drawing. In Virtual Reality, however, input is largely detected using cameras which does not nearly reach the fidelity we achieve with analog handwriting. In this paper, we present Flashpen, a digital pen for VR whose sensing principle affords accurately digitizing hand-writing.",,Expo Hall B,C28
PO1020,Virtual Reality for Remote Controlled Robotics in Engineering Education,Andrew Rukangu: University of Georgia; Alexander James Tuttle: University of Georgia; Kyle Johnsen: University of Georgia,"There is a high demand for high-end lab equipment in engineering education, especially for courses that require practical hands-on lab exercises. However, this equipment is quite expensive which forces some institutions to seek other alternatives or forego them altogether. In this work, use virtual and augmented reality to build and test a remote UR-10 based robotics lab that allows students to work together on a hands-on robotics-based lab.",,Expo Hall A,C23
PO1021,Development of a Virtual Reality Assessment of Visuospatial Function and Oculomotor Control,Garima Adlakha: University of Southern California; Sanya Singh: University of Southern California; Kranthi Nuthalapati: University of Southern California; Apoorva Aravind Patil: University of Southern California; Prajakta Khandve: University of Southern California; Pushpak Bhattacharyya: University of Southern California; Saravanan Manoharan: University of Southern California; Sanjay Mallasamudram Santhanam: University of Southern California; Isaiah J Lachica: University of Southern California; James M. Finley: University of Southern California; Vangelis Lympouridis: USC,"This demo uses Virtual Reality (VR) to assess cognitive function in people with Parkinson's disease. We developed a VR-based assessment that combines simple game mechanics with components of the Trail Making Test. We collect performance metrics and gaze analytics during gameplay using the HTC Vive Pro Eye system. Ultimately, this data will allow clinicians and researchers to characterize cognitive and visuomotor deficits in people with neurological impairments such as Parkinson's disease.",https://www.youtube.com/watch?v=i_oVs7FsGFg,Expo Hall A,C22
PO1022,A Real-time approach to improve drilling decision-making process using virtual reality visualizations,Thiago Malheiros Porcino: SENAI ISI SVP - Firjan; Márcia M. Dórea: SENAI ISI SVP - Firjan; Diego Barboza: SENAI ISI SVP - Firjan; Wesley Oliveira: SENAI ISI SVP - Firjan; Eric Romani: SENAI ISI SVP - Firjan; Fernando Perin Munerato: Repsol Sinopec Brazil; João H. Batista: Repsol Sinopec Brazil,"Virtual reality (VR) is one of the key Industry 4.0 trends and is being largely used for training and simulations. A VR environment can reduce training and drilling analysis costs, and help operators and coordinators to monitor the trajectory and other operational variables during the drilling process. This paper presents Divisor, a virtual reality tool for monitoring variables and analyzing historical and real-time data while drilling a new oil well.",https://www.youtube.com/watch?v=emN2dskuOLg,Expo Hall A,C27
PO1024,Shared Augmented Reality Experience Between a Microsoft Flight  Simulator User and a User in the Real World,Christoph Leuze: Nakamir Inc; Matthias Leuze: Alpinschule Innsbruck,"Our demo consists of an application that allows a user with an AR display (smartphone or Hololens 2) to watch another user, flying an airplane in the Microsoft Flight Simulator 2020 (MSFS), at their respective location in the real world. To do that, we take the location of a plane in MSFS, and stream it via a server to a mobile AR device. The mobile device user can then see the same 3D plane model move at exactly that real world location, that corresponds to the plane’s virtual MSFS location.",https://youtu.be/ngPJNtdsviU,Expo Hall A,C21
PO1024b,Real-time Mixed Reality Teleconsultation for Intensive Care Units in Pandemic Situations,"Daniel Roth (Computer Aided Medical Procedures and Augmented Reality); Kevin Yu (Research Group MITI); Frieder Pankratz (LMU); Gleb Gorbachev (Computer Aided Medical Procedures and Augmented Reality); Andreas Keller (Computer Aided Medical Procedures and Augmented Reality); Marc Lazarovici (Institut für Notfallmedizin); Dirk Wilhelm (Research Group MITI); Simon Weidert (Orthopedic Trauma Surgery, Ludwig-Maximillian University); Nassir Nawab (Computer Aided Medical Procedures and Augmented Reality); Ulrich Eck: Computer Aided Medical Procedures and Augmented Reality","This demo depicts a COVID-19 ICU station patient visit. Through our system, remote experts can join a COVID -19 ICU patient visit without physically moving in the hospital, which avoids gatherings and personnel traffic and optimizes resources.",,Expo Hall B,C27
PO1025,Turning a Messy Room into a Fully Immersive VR Playground,Naoki Matsuo: Kwansei Gakuin University; Masataka Imura: Kwansei Gakuin University,"In this study, to enable a VR experience with an HMD even in a space with obstacles, we constructed a reality-based VR space in real time that does not impair the worldview even in a space with obstacles. In addition, we aim to construct a VR space that is easier to recognize by classifying ``objects that are boundaries of space'' and ``ordinary obstacles'' using a deep learning network and superimposing virtual objects corresponding to each type of real object.",https://www.youtube.com/watch?v=JQmwr8seeIM&t=9s,Expo Hall B,C22
PO1026,Demonstrating Rapid Touch Interaction in Virtual Reality through Wearable Touch Sensing,Manuel Meier: ETH Zürich; Paul Streli: ETH Zürich; Andreas Rene Fender: ETH Zürich; Christian Holz: ETH Zürich,"We bring quick touch interaction to Virtual Reality, illustrating the beneficial use of rapid tapping, typing, and surface gestures for Virtual Reality. The productivity scenarios that become possible are reminiscent of apps that exist on today's tablets. We use a wrist-worn prototype to complement the optical hand tracking from VR headsets with inertial sensing to detect touch events on surfaces. Our demonstration comprises UI control in word processors, web browsers, and document editors.",https://www.youtube.com/watch?v=cZl_Sn2dhZY,Expo Hall B,C26
PO1027,Virtual Control Interface: Discover and Control IoT devicesintuitively through AR glasses with Multi-model Interactions,Zezhen Xu: University of Southern California; Vangelis Lympouridis: USC,"The number of smart home devices will increase exponentially. The current Internet of Things (IoT) control interfaces on smartphones are spatially separated from the devices they operate, making them less intuitive and progressively more complicated. We developed VCI, a Virtual Reality (VR) simulation for HCI researchers to explore multimodal interactions with IoT in a future smart home setting using virtual control interfaces projected on emulated AR glasses.",https://youtu.be/K3CGRsZ1sqc,Expo Hall A,C25
PO2029,Revealable Volume Displays: 3D Exploration of Mixed-Reality Public Exhibitions,Fatma Ben Guefrech: Université de Lille; Florent Berthaut: Université de Lille; Patricia Plénacoste: Université de Lille; Yvan Peter: Université Lille 1; Laurent Grisoni: University of Lille,"We present a class of mixed-reality displays which allow for the 3D exploration of content in public exhibitions, that we call Revealable Volume Displays (RVD). They allow visitors to reveal information placed freely inside or around protected artefacts, visible by all, using their reflection in the panel. We first discuss the implementation of RVDs, providing both projector-based and mobile versions. We then present a design space that describes the interaction possibilities that they offer. Drawing on insights from a field study during a first exhibition, we finally propose and evaluate techniques for facilitating 3D exploration with RVDs.",https://www.youtube.com/watch?v=waN7LQpy8bM,Expo Hall B,C24
PO2278,Magnoramas,Kevin Yu: Research Group MITI; Alexander Winkler: Technical University of Munich; Frieder Pankratz: LMU; Marc Lazarovici: Institut für Notfallmedizin; Prof. Dirk Wilhelm: Research Group MITI; Ulrich Eck: Computer Aided; Medical Procedures and Augmented Reality; Daniel Roth: Computer Aided Medical Procedures and Augmented Reality; Nassir Navab: Technische Universität München,"We introduce Magnoramas, an interaction method for creating supernaturally precise annotations on virtual objects. We evaluated Magnoramas in a collaborative context in a simplified clinical scenario. Teleconsultation was performed between a remote expert inside a 3D reconstruction and embodied by an avatar in Virtual Reality that collaborated with a local user through Augmented Reality. The results show that Magnoramas significantly improve the precision of annotations while preserving usability and perceived presence measures compared to the baseline method. By additionally hiding the physical world while keeping the Magnorama, users can intentionally lower their perceived social presence and focus on their tasks.",https://youtu.be/3g9MDfUugjg,Expo Hall B,C21
PO2308,Visualizing Planetary Spectroscopy through Immersive On-site Rendering,Lauren Gold: Arizona State University; Alireza Bahremand: Arizona State University; Connor Richards: Arizona State University; Justin Hertzberg: Arizona State University; Kyle Sese: Arizona State University; Alexander A Gonzalez: Hamilton High School; Zoe Purcell: Arizona State University; Kathryn E Powell: Northern Arizona University; Robert LiKamWa: Arizona State University,"Planetary Visor is our virtual reality tool to visualize orbital and rover-based datasets from the ongoing traverse of the NASA Curiosity rover in Gale Crater. Data from orbital spectrometers provide insight about the composition of planetary terrains. Meanwhile, Curiosity rover data provide fine-scaled localized information about Martian geology. By visualizing the intersection of the orbiting instrument's field of view with the rover-scale topography, and providing interactive navigation controls, Visor constitutes a platform for users to intuitively understand the scale and context of the Martian geologic data under scientific investigation.",https://youtu.be/Wz3Nzo09qko,Expo Hall A,C24