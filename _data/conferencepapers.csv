id,Title,Contact Name,Contact Email,abstract,authors,url
C2008,Evaluating User Acceptance using WebXR for an Augmented Reality Information System,Fabian Meyer,fabian.meyer@stud.hs-ruhrwest.de,"Augmented Reality has a long history and has seen major technical advantages in the last years. With WebXR, a new web standard, Mobile Augmented Reality (MAR) applications are now available in the web browser. This eliminates one of the biggest obstacles for users in accessing advanced, markerless AR environments on the smartphone, as it makes installing additional software obsolete. Through the prototypical implementation of an AR information system in the form of a web app and a case study, we were able to show that this relatively new browser API can indeed be used for such complex application areas.",Fabian Meyer: Hochschule Ruhr West University of Applied Sciences; Christian Gehrke: Hochschule Ruhr West University of Applied Sciences; Michael Schäfer: Institute Computer Science,
C2012,A practical  framework of multi-person 3D human pose estimation with a single RGB camera,Weiliang Meng,weiliang.meng@ia.ac.cn,"We propose a practical framework named 'DN-2DPN-3DPN' for multi-person 3D pose estimation with a single RGB camera. Our framework performs three-stages tasks on the input video: our DetectNet(DN) firstly detects the people's bounding box individually for each frame of the video, while our 2DPoseNet(2DPN)  estimates the 2D poses
for each person in the second stage, and our 3DPoseNet(3DPN) is finally applied to obtain the 3D poses of the people. Experiments validate that our method can achieve
 state-of-the-art performance for multi-person 3D human pose estimation on the Human3.6M dataset.","Le Ma: Institute of Automation，Chinese Academy of Sciences; Sen Lian: Institute of Automation，Chinese Academy of Sciences; Shandong Wang: Intel Labs China; Weiliang Meng: Zhejiang Lab; Jun Xiao: University of Chinese Academy of Sciences; Xiaopeng ZHNAG: Institute of Automation, Chinese Academy of Sciences",
C2014,Design and Evaluation of a Free-Hand VR-based Authoring Environment for Automated Vehicle Testing,Sevinc Eroglu,eroglu@vr.rwth-aachen.de,"We propose a VR authoring environment that enables engineers to design road networks and traffic scenarios for automated vehicle testing based on free-hand interaction. We present a 3D interaction technique for the efficient placement and selection of virtual objects that is employed on a 2D panel. We conducted a comparative user study in which our interaction technique outperformed existing approaches regarding precision and task completion time. Furthermore, we demonstrate the effectiveness of the system by a qualitative user study with domain experts.",Sevinc Eroglu: RWTH Aachen University; Frederic Stefan: Ford Motor Company; Alain M.R. Chevalier: Ford Research Center Aachen; Daniel Roettger: Ford Motor Company; Daniel Zielasko: University of Trier; Torsten Wolfgang Kuhlen: RWTH Aachen University; Benjamin Weyers: Trier University,
C2020,Unident: Providing Impact Sensations on Handheld Objects via High-Speed Change of the Rotational Inertia,Shuntaro Shimizu,s_shimizu@cyber.t.u-tokyo.ac.jp,"We propose Unident, a handheld proxy capable of providing impact sensations by changing its rotational inertia at a high speed. Unident allows providing impact sensations at a high frequency with low latency and power consumption. In the first experiment, we demonstrated that Unident can physically provide an impact sensation applied to a handheld object by analyzing the pressure on the user's palm. The second experiment showed that Unident can provide an impact sensation with various magnitudes depending on the amount of rotational inertia to be changed. In the user study, Unident could provide more realistic impact sensations than vibrotactile feedback.",Shuntaro Shimizu: The University of Tokyo; Takeru Hashimoto: The University of Tokyo; Shigeo Yoshida: The University of Tokyo; Reo Matsumura: karakuri products Inc.; Takuji Narumi: The University of Tokyo; Hideaki Kuzuoka: The University of Tokyo,https://youtu.be/bNRKsab2y6c
C2021,A Protocol for Dynamic Load Distribution in Web-Based AR,Rajath Jayashankar,jayashankar.rajath1335@gmail.com,"In a Web-based Augmented Reality (AR) application, to achieve an immersive experience we require precise object detection, realistic model rendering, and smooth occlusion in real-time. To achieve these objectives on a device requires heavy computation capabilities unavailable on most mobile devices, this can be solved by using cloud computing but it introduces network latency issues. In this work, we propose a new network protocol named DLDAR (Dynamic Load Distribution in Web-based AR) that facilitates and standardizes methods for dynamic division of compute between client and server based on device and network condition to min-max latency and quality.",Rajath Jayashankar: Cochin University of Science and Technology; Akul Santhosh: Cochin University of Science and Technology; Sahil athrij: Cochin University of Science and Technology; Arun Padmanabhan: Cochin University of Science and Technology; Sheena Mathew: Cochin University of Science and Technology,
C2026,Promoting Reality Awareness in Virtual Reality Through Proxemics,Daniel Medeiros,danielpiressm@gmail.com,"Head-Mounted Virtual reality (VR) systems render people oblivious to the outside, placing them in unsafe situations. Existing research proposed alert-based solutions to address this. Our work takes a different angle. We focus on: (i) exploring alerts to make VR users aware of non-immersed bystanders' in non-critical contexts; (ii) understanding how best to make non-immersed bystanders noticed while maintaining a presence in VR. To this end, we leveraged proxemics, perception channels, and push/pull approaches evaluated via two user studies. Our findings indicate a strong preference towards maintaining immersion, combining audio/visual cues, push and pull notification techniques that evolve dynamically based on proximity.",Daniel Medeiros: University of Glasgow; Rafael Kuffner dos Anjos: University College London; Nadia Pantidi: Victoria University of Wellington; Kun Huang: Victoria University of Wellington; Mauricio Sousa: University of Toronto; Craig Anslow: Victoria University of Wellington; Joaquim P Jorge: INESC-ID,
C2028,Digital Twin as A Mixed Reality Platform for Art Exhibition Curation,Inhwa Yeom,yinhwa@kaist.ac.kr,"We present a digital twin-based Mixed Reality platform for arts curators. Despite the rising presence of exhibitions in varying digital formats, the virtual engagement of arts curators has been nearly disabled. To replicate and enhance the professional capability of arts curators in the virtual realm, our system integrates a digital twin art space and 3D authoring techniques, aided with spatial and semantic metadata. Our user evaluation proves the system's usability, and its capacity to support curatorial activities. With this, we aim to provide a groundwork to similar systems that also extend arts curator’s creativity and outreach beyond time and space.",Inhwa Yeom: KAIST; Woontack Woo: KAIST,
C2029,Revealable Volume Displays: 3D Exploration of Mixed-Reality Public Exhibitions,Dr Fatma Ben Guefrech,fatima.benguefrech@univ-lille.fr,"We present a class of mixed-reality displays which allow for the 3D exploration of content in public exhibitions, that we call Revealable Volume Displays (RVD). They allow visitors to reveal information placed freely inside or around protected artefacts, visible by all, using their reflection in the panel. We first discuss the implementation of RVDs, providing both projector-based and mobile versions. We then present a design space that describes the interaction possibilities that they offer. Drawing on insights from a field study during a first exhibition, we finally propose and evaluate techniques for facilitating 3D exploration with RVDs.",Fatma Ben Guefrech: Université de Lille; Florent Berthaut: Université de Lille; patricia plénacoste: université de lille ; Yvan Peter: Université Lille 1; Laurent Grisoni: university of lille,
C2035,Is Virtual Reality sickness elicited by illusory motion affected by gender and prior video gaming experience?,Miss Katharina Margareta Theresa Pöhlmann,kpohlmann@lincoln.ac.uk,"Gaming using VR headsets is becoming increasingly popular; however, these displays can cause VR sickness.
To investigate the effects of gender and gamer type on VR sickness motion illusions are used as stimuli, being a novel method of inducing the perception of motion whilst minimising the ``accommodation vergence conflict''.
Females and those who do not play action games experienced more severe VR sickness symptoms compared to males and experienced action gamers. The interaction of the gender and gamer type revealed that prior video gaming experience was beneficial for females, however, for males, it did not show the same positive effects.",Katharina Margareta Theresa Pöhlmann: University of Lincoln; Louise O'Hare: Nottingham Trent University; Julia Föcker: University of Lincoln; Adrian Parke: University of the West of Scotland; Patrick Dickinson: University of Lincoln,
C2037,"""Through the Solar System"" ——XR science education system based on multiple monitors",Professor YanXiang Zhang,petrel@ustc.edu.cn,"This paper presents a multi-user extended reality (XR) science education system based on multiple monitors. It effectively uses existing equipment and space, allowing teachers and students to share immersive virtual scenes, increasing the possibility of collaboration, and attracting students through interactive interfaces and plot designs. Actively learn scientific knowledge, face-to-face communication, and interaction, thereby enhancing the effect of science education.",YanXiang Zhang: University of Science and Technology of China; JiaYu Wang: University of Science and Technology of China,
C2046,Toward Understanding the Effects of Virtual Character Appearance on Avoidance Movement Behavior,Christos Mousas,christosmousas@gmail.com,"This virtual reality study was conducted to assess the impact of the appearance of virtual characters on the avoidance movement behavior of participants. Under each condition, one of the five different virtual characters (classified as mannequin, human, cartoon, robot, and zombie) was studied. Based on the collected measurements (avoidance movement behavior and self-reported ratings), we tried to understand the effects of the appearance of a virtual character on the avoidance movement behavior. The results obtained from this study indicated that the appearance of the virtual characters did affect the avoidance movement behavior and also some of the examined concepts.",Christos Mousas: Purdue University; Alexandros Fabio Koilias: University of the Aegean; Banafsheh Rekabdar: Southern Illinois University; Dominic Kao: Purdue University; Dimitris Anastasiou: Southern Illinois University,
C2047,Impossible Staircase: Vertically Real Walking in an Infinite Virtual Tower,Jen-Hao Cheng,andytony56791@gmail.com,"We present Impossible Staircase, a real-walking virtual reality system that allows users to climb an infinite virtual tower. Our set-up consists of an one-level scaffold and a lifter. A user climbs up the scaffold by real walking on a stairway while wearing a head-mounted display, and gets reset to the ground level by a lifter imperceptibly. By repeating this process, the user perceives an illusion of climbing an infinite number of levels. We built a working system and demonstrated it with a 15-min experience. With the working system, we conducted user studies to gain deeper insights into vertical motion simulation and vertical real walking in virtual reality.",Jen-Hao Cheng: National Taiwan University; Yi Chen: National Taiwan University; Ting-Yi Chang: National Taiwan University; Hsu-En Lin: National Taiwan University; Po-Yao (Cosmos) Wang: National Taiwan University; Lung-Pan Cheng: National Taiwan University,
C2048,Climaxing VR Character with Scene-Aware Aesthetic Dress Synthesis,Sifan Hou,3120191002@bit.edu.cn,"In this paper, we propose a new problem of synthesizing appropriate dress for a virtual character based on the analysis of the scenario where he/she showes up. We come up with a pipeline to tackle the scenario-aware dress synthesis problem. Firstly, given a scene, our approach predicts a dress code from the extracted high-level information in the scene, consisting of season, occasion, and scene category. Then our approach tunes the dress details to fit the aesthetic criteria and the virtual character's attributes. The tuning process is implemented by an optimization of a cost function. We carried out experiments to validate the efficacy of the proposed approach. The perceptual study results show the good performance of our approach.",Sifan Hou: Beijing Institute of Technology; Yujia Wang: Beijing Institute of Technology; Wei Liang: Beijing Institute of Technology; Bing Ning: Beijing Institute of Fashion Technology,
C2050,The Embodiment of Photorealistic Avatars Influences Female Body Weight Perception in Virtual Reality,Erik Wolf,erik.wolf@uni-wuerzburg.de,"In our work, we compared body weight perception of 56 female participants in VR. They either (a) embodied a photorealistic, non-personalized virtual human and performed body movements or (b) only observed it performing the same movements without embodying it. Afterward, participants had to estimate the virtual human's body weight. Additionally, we considered the influence of the participants' BMI on the estimations and captured the participants' feelings of presence and embodiment. Participants embodying the virtual human estimated the body weight significantly lower. Furthermore, the estimations of body weight were significantly predicted by the participant's BMI with embodiment, but not without.","Erik Wolf: University of Würzburg, Department of Computer Science, HCI Group; Nathalie Merdan: University of Würzburg; Nina Döllinger: Julius-Maximilians-Universität; David Mal: Universit of Würzburg, Department of Computer Science, HCI Group; Carolin Wienrich: University Würzburg; Mario Botsch: TU Dortmund University; Marc Erich Latoschik: Department of Computer Science, HCI Group",
C2052,Visualization and Manipulation of Air Conditioner Flow via Touch Screen,Dr. Jason Orlosky,jasonorlosky@gmail.com,"In this paper, we present a smartphone controlled interface for both manipulating A/C air flow and visualizing the resulting output as a 3D Augmented Reality (AR) overlay. In contrast with previous work, we generate airflow models based on the A/C's exhaust vents, allowing users to see the effects of interactions on airflow in real time. We also implemented and tested three different methods for manipulation including, swipe, drag and button based manipulations using finger or device gestures. Experiments showed that participants (N=50) were able to control air flow most quickly with the swipe based interface, which outperformed the drag and button median completion times by 26.5% and 36.1%, respectively.",Wei Yaguang: Osaka University; Jason Orlosky: Osaka University; Tomohiro Mashita: Osaka Univercity,
C2063,Virtual Reality in transit: how acceptable is VR use on public transport?,Laura Bajorunaite,l.bajorunaite.1@research.gla.ac.uk,"When travelling on public transport, passengers use devices such as mobile phones or laptops to pass the time. VR (Virtual Reality) head-mounted displays could provide advantages over these devices by delivering personal and private experiences that help the wearer escape their confined space. This paper presents the key factors that influence VR acceptance on different modes of public transport (from buses to aeroplanes), uncovered through two surveys (N1=60, N2=108). An initial analysis of responses revealed unique passenger needs and challenges currently preventing wider VR adoption, creating parameters for future research.",Laura Bajorunaite: University of Glasgow; Stephen Brewster: University of Glasgow; Julie R. Williamson: University of Glasgow,
C2065,A-Visor and A-Camera: Arduino-based Cardboard Head-Mounted Controllers for VR Games,Prof. Kibum Kim,kibum@hanyang.ac.kr,"The Nintendo Labo: VR Kit introduced several types of cardboard controllers that allow users to enjoy virtual reality through various interactions. However, it is not compatible with smartphone devices which many people can use to access VR easily. In this study, we used Arduino and a smartphone to create two customized low-cost cardboard head-mounted VR controllers which we called A-Visor and A-Camera. We also created VR games for A-Visor and A-Camera using Unity3D. Thus, we present new DIY head-mounted VR controllers that are made by assembling corrugated cardboard materials, Arduino, and sensors, which are readily accessible to DIY enthusiasts.",Sangmin Park: Hanyang University; Hojun Aan: Hanyang University; Junhyeong Jo: Hanyang University; Hyeonkyu Kim: Hanyang University; Sangsun Han: Hanyang University; Jimoon Kim: Hanyang University; Pilhyoun Yoon: Hanyang University; Kibum Kim: Hanyang University,
C2068,Hand-by-Hand Mentor: An AR based Training System for Piano Performance,Ruoxi Guo,rebeccag@buaa.edu.cn,"Multimedia instrument training has gained great momentum benefiting from augmented and/or virtual reality (AR/VR) technologies. We present an AR-based individual training system for piano performance that uses only MIDI data as input. Based on fingerings decided by a pre-trained Hidden Markov Model (HMM), the system employs musical prior knowledge to generate natural-looking 3D animation of hand motion automatically. The generated virtual hand demonstrations are rendered in head-mounted displays and registered with a piano roll. Two user studies conducted by us show that the system requires relatively less cognitive load and may increase learning efficiency and quality.",Ruoxi Guo: Beihang University; Jiahao Cui: Beihang University; Wanru Zhao: Beihang University; Shuai Li: Beihang University; Aimin Hao: Beihang University,
C2069,Impact of Avatar Anthropomorphism and Task Type on Social Presence in Immersive Collaborative Virtual Environments,Geoffrey Gorisse,geoffrey.gorisse@ensam.eu,"Eliciting a sense of social presence is necessary to create believable
multi-user situations in immersive virtual environments. To be able to collaborate in virtual worlds, users are represented by avatars (virtual characters controlled in real time) allowing them to interact with each other. We report a study investigating the impact on social presence of both non-human avatars' facial properties and of the type of collaborative task being performed by the users (asymmetric collaboration versus negotiation). While we observed no significant impact of facial properties, both co-presence and perceived message understanding scores were significantly higher during the negotiation task.",Charlotte Dubosc: Arts et Métiers Institute of Technology; Geoffrey Gorisse: Arts et Métiers Institute of Technology; Olivier Christmann: Arts et Métiers Institute of Technology; Sylvain Fleury: Arts et Métiers Institute of Technology; Killian Poinsot: Arts et Métiers Institute of Technology; Simon Richir: Arts et Métiers Institute of Technology,
C2070,Blink-Suppressed Hand Redirection,André Zenner,andre.zenner@dfki.de,"We present Blink-Suppressed Hand Redirection (BSHR), the first body warping technique that makes use of blink-induced change blindness, to study the feasibility and detectability of hand redirection based on blink suppression. In a psychophysical experiment, we verify that unnoticeable blink-suppressed hand redirection is possible and derive corresponding detection thresholds. Our findings also indicate that the range of unnoticeable BSHR can be increased by combining blink-suppressed instantaneous hand shifts with continuous warping. As an additional contribution, we derive detection thresholds for Cheng et al.'s (2017) body warping technique that does not leverage blinks.","André Zenner: Saarland University, Saarland Informatics Campus; Kora Persephone Regitz: Saarland University, Saarland Informatics Campus; Antonio Krüger: Saarland University, Saarland Informatics Campus",
C2085,The Effect of Pitch in Auditory Error Feedback for Fitts’ Tasks in Virtual Reality Training Systems,Anil Ufuk Batmaz,abatmaz@sfu.ca,"We examine the effect of different pitches for auditory error feedback on pointing performance. The results of our first study demonstrate that high-pitch error feedback significantly decreases user performance in terms of time and throughput. In a second study, we evaluated adaptive sound feedback, i.e., we increased the pitch with the error rate, while asking subjects to execute the task “as fast/as precise/as fast and precise as possible”. Results showed that adaptive sound feedback decreases the error rate for “as fast as possible” task execution without affecting the time. Our results inform the design of various VR systems.",Anil Ufuk Batmaz: Simon Fraser University ; Wolfgang Stuerzlinger: Simon Fraser University,
C2090,Detection Thresholds with Joint Horizontal and Vertical Gains in Redirected Jumping,Yi-Jun Li,yaoling@buaa.edu.cn,"Redirected jumping (RDJ) is a locomotion technique that allows users to explore a virtual space larger than the available physical space by imperceptibly manipulating users’ virtual viewpoints according to different gains. To figure out how humans perceive distance manipulation when more than one gain is used, we explored joint horizontal and vertical gains during two-legged takeoff jumping. We estimated and analyzed horizontal and vertical detection thresholds by conducting a user study, fitting the data to two-dimensional psychometric functions, and visualizing the fitted 3D plots. We also designed redirected jumping-based games and demonstrated the effectiveness of RDJ.","Yi-Jun Li: Beihang University; De-Rong Jin: Beihang University; Miao Wang: Beihang University; Junlong Chen: Beihang University; Frank Steinicke: Universität Hamburg; Shi-Min Hu: BNRist, Tsinghua University; Qinping Zhao: Beihang University",
C2093,Effects of Immersion and Visual Angle on Brand Placement Effectiveness,Sebastian Oberdörfer,sebastian.oberdoerfer@uni-wuerzburg.de,"Typical inherent properties of immersive Virtual Reality (VR) such as felt presence might have an impact on how well brand placements are remembered. In this study, we exposed participants to brand placements in four conditions of varying degrees of immersion and visual angle on the stimulus. Placements appeared either as poster or as puzzle. We measured the recall and recognition of these placements. Our study revealed that neither immersion nor the visual angle had a significant impact on memory for brand placements.","Sebastian Oberdörfer: University of Würzburg; Samantha Straka: University of Würzburg; Marc Erich Latoschik: Department of Computer Science, HCI Group",
C2094,Measuring the Effects of Virtual Environment Design on Decision-Making,Sebastian Oberdörfer,sebastian.oberdoerfer@uni-wuerzburg.de,"Recent research indicates an impairment in decision-making in immersive Virtual Reality (VR) when completing the Iowa Gambling Task (IGT). There is a high potential for emotions to explain the IGT decision-making behavior. The design of a virtual environment (VE) can influence a user's mood and hence potentially the decision-making. In a novel user study, we measure decision-making using three virtual versions of the IGT. The versions differ with regard to the degree of immersion and design of the VE. Our results revealed no significant impact of the VE on the IGT and hence on decision-making.","Sebastian Oberdörfer: University of Würzburg; David Heidrich: German Aerospace Center (DLR); Sandra Birnstiel: University of Würzburg; Marc Erich Latoschik: Department of Computer Science, HCI Group",
C2095,"The influence of hand visualization in tool-based motor-skills training, a longitudinal study",Dr. Aylen Ricca,aricca8@gmail.com,"In this work, we study how the user's hand representation impacts the training of tool-based motor skills in immersive VR. We created a VR trainer for a tool-based task, and conducted a user study (N=26) to evaluate how the hand visualization can influence participants' learning performance. Two groups of participants were trained in the simulator under one of the two experimental conditions: presence/absence of their virtual hands' representation, while a control group received no training. The results show that while both training groups improve their performance compared to the control group, no significant impact of the hand visualization is observed.","Aylen Ricca: IBISC, Univ Evry, Université Paris-Saclay; Amine Chellali: IBISC, Univ Evry, Université Paris-Saclay; Samir Otmane: IBISC, Univ Evry, Université Paris-Saclay",
C2096,Realistic 3D Swept-Volume Display with Hidden-Surface Removal Using Physical Materials,Ray Asahina,asahina.r.aa@m.titech.ac.jp,"Swept-volume displays can provide accurate physical cues for depth perception. However, the corresponding texture reproduction does not have high quality because they employ high-speed projectors with low bit-depth and low resolution. To address such limitation while retaining their advantages, we propose a novel swept-volume display by incorporating physical materials as screens. Physical materials such as wool, felt, and so on are directly used for reproducing textures on a displayed 3D surface. Furthermore, we introduce the adaptive pattern generation based on viewpoint tracking for the hidden-surface removal. Our algorithm leverages the ray-tracing concept and can run at high speed on GPU.",Ray Asahina: Tokyo Institute of Technology; Takashi Nomoto: Tokyo Institute of Technology; Takatoshi Yoshida: Massachusetts Institute of Technology; Yoshihiro Watanabe: Tokyo Institute of Technology,
C2098,Learning Hawaiian Open Ocean Navigation Methods with Kilo Hōkū VR,Patrick Karjala,pkarjala@hawaii.edu,"Kilo Hōkū VR (t: “to observe and study the stars”) is a virtual reality simulation of the Hōkūleʻa, a Polynesian double-hulled sailing canoe, and the practice of Modern Hawaiian wayfinding, or non-instrument open ocean navigation. It was developed to assist in the cultural preservation of the celestial navigation portion of Modern Hawaiian wayfinding, and to expand the availability of learning opportunities. We here introduce new features added to the simulation for teacher and student interaction and learning. We observed the potential viability of using Kilo Hōkū VR with students who are currently learning wayfinding in a classroom setting.",Patrick Karjala: University of Hawaiʻi at Mānoa; Dean Lodes: University of Hawai‘i at Mānoa; Anna Sikkink: University of Hawaii at Manoa; Kari Noe: University of Hawaii at Manoa; Jason Leigh: University of Hawaii at Manoa,
C2100,Augmented Reality for Maritime Navigation Assistance - Egocentric Depth Perception in Large Distance Outdoor Environments,Julia Hertel,hertel@informatik.uni-hamburg.de,"Augmented reality (AR) provides potential for navigation assistance interfaces in maritime contexts by displaying information directly into the user's field of view.
Therefore, it is crucial to understand how egocentric distances of displayed objects are perceived and how different design attributes influence depth estimation.
While previous work mainly focused on depth perception in short-distance indoor environments, this paper presents a perceptual matching task in a wide outdoor environment.
Our results suggest a distance overestimation across all tested distances and significant influences of (i) shape, (ii) coloration, and (iii) relation to floor.
Additionally, we explored potential design implications in a pilot study on a ship.",Julia Hertel: University of Hamburg; Frank Steinicke: Universität Hamburg,
C2105,Diegetic Tool Management in a Virtual Reality Training Simulation,Patrick Dickinson,pdickinson@lincoln.ac.uk,"Researchers have suggested that diegetic interfaces can enhance users’ sense of presence and immersion in virtual reality. We present a study (N = 58) in which we compare participants’ experiences of diegetic and non-diegetic interfaces, in a prototype VR CSI training application. Contrary to expectations, we do not find evidence that participants’ sense of presence is elevated when using the diegetic interface; however, we suggest that this may be due to reported higher levels of perceived workload. We conclude by discussing the relationship between diegetic interface design and interaction fidelity, and highlighting trade-offs between fidelity and engagement.",Patrick Dickinson: University of Lincoln; Andrew Cardwell: University of Lincoln; Adrian Parke: University of the West of Scotland; Kathrin Gerling: KU Leuven; John C Murray: University of Hull,
C2108,Using Siamese Neural Networks to Perform Cross-System Behavioral Authentication in Virtual Reality,Sean Banerjee,sbanerje@clarkson.edu,"We provide an approach on using behavioral biometrics to perform cross-system high-assurance authentication of users in VR  environments. Traditional PIN or password-based credentials can be breached by malicious impostors, or be handed over by an intended user of a VR system to a confederate. We use Siamese neural networks to characterize systematic differences between data across pairs of dissimilar VR systems. We provide equal error rates (EERs) ranging from 1.38% to 3.86% for authentication and identification accuracies ranging from 87.82% to 98.53% using a dataset consisting of 41 users performing ball-throwing with 3 VR systems.",Robert Miller: Clarkson University; Natasha Kholgade Banerjee: Clarkson University; Sean Banerjee: Clarkson University,
C2109,Unscripted Retargeting: Reach Prediction for Haptic Retargeting in Virtual Reality,Aldrich Clarence,aldrich.clarence@monash.edu,"Research is exploring novel ways of adding haptics to VR. One popular technique is haptic retargeting, where real and virtual hands are decoupled to enable the reuse of physical props. However, this technique requires the system to know the users’ intended interaction target, or requires additional hardware for prediction. We explore software-based reach prediction as a means of facilitating responsive, unscripted retargeting. We trained a Long Short-Term Memory network on users’ reach trajectories to predict intended targets. We achieved an accuracy of 81.1% at approximately 65% of movement. This could enable haptic retargeting during the last 35% of movement. We discuss the implications for possible physical proxy locations.",Aldrich Clarence: Monash University; Jarrod Knibbe: University of Melbourne; Maxime Cordeil: Monash University; Michael Wybrow: Monash University,
C2112,AREarthQuakeDrill: Toward Increased Awareness of Personnel during Earthquakes via AR Evacuation Drills,Kohei Yoshimi,yoshimi.kohei@lab.ime.cmc.osaka-u.ac.jp,"Evacuation drills are carried out to reduce the injury or death caused by the earthquake. However, the content of evacuation drills is fixed to confirm evacuation routes and actions. This immutability reduces user motivation and sincerity.

In this paper, we propose Augmented Reality (AR) based evacuation drills. We use an optical see-through head-mounted display for mapping and recognizing the room interior. Our system constructs an AR drill environment of the real environment with the after-effects of the earthquake disaster.

We evaluated our system by experiments with 10 participants. Comparing cases with and without AR obstacles, we found that our AR system affected participants' motivation and diversity of evacuation routes.",Kohei Yoshimi: Information Engineering System; Photchara Ratsamee: Osaka Univercity; Jason Orlosky: Osaka University,
C2114,"CAVE vs. HMD, in Distance Perception",Théo COMBE,combetheo@gmail.com,"This study aims to analyze differences between a CAVE system and a Head-Mounted Display (HMD), two technologies presenting important differences, focusing on distance perception, as past research on this factor is usually carried with only one or the other device. We performed two experiments. First, we explored the impact of the HMD's weight, by removing any other bias. Second, we compared distance perception using a simple hand interaction in a replicated environment. Results reveal that the HMD's weight has no significant impact over short distances, and the usage of a virtual replica was found to improve distance perception.","Théo COMBE: Institut Image; Jean-Rémy Chardonnet: Arts et Métiers, Institut Image; Frederic Merienne: Arts et Metiers; Jivka Ovtcharova: Institute for Information Management in Engineering",
C2115,Interactive Context-Aware Furniture Recommendation using Mixed Reality,Hongfei Yu,michael_yu0906@163.com,"We present a Mixed Reality (MR) system,  through Hololens,  to provide context-aware furniture recommendation in an interactive fashion. Firstly, a ranking-based metric learning method is adopted to represent the furniture compatibility through a latent space. Then,in the recommendation process, a physical scene is captured by the cameras mounted on the MR device, and two types of scene contextare analyzed: (1) category context; (2) spatial context. At last, the one with the minimal weighted ranking distance in the latent spaceis recommended to the user. With MR devices, a user could perceiveand manipulate the recommended furniture in real-time. We conductuser study to validate the efficacy of the proposed system.","Hongfei Yu: Beijing Institute of Technology; Wei Liang: Beijing Institute of Technology; Shihao Song: Beijing Institute of Technology; Bing Ning: School of Computer Science, Beijing Institute of Technology; Yixin Zhu: UCLA",
C2124,Requirements Gathering for VR Simulators for Training: Lessons Learned for Globally Dispersed Teams,Vivian Gómez,vn.gomez@uniandes.edu.co,"We report an empirical study on the use of current VR technologies for requirements gathering in the field of simulation and training. We used synchronous and asynchronous traditional techniques plus collaborative virtual environments such as MozillaHubs and AltspaceVR. Our results show that requirements gathering in VR makes a difference in the process of requirements identification. We report advantages and shortcomings that can be useful for future practitioners. For example, we found that VR sessions allowed for better identification of dimensions and sizes. VR sessions for requirements gathering could also benefit from better pointers and better sound",Vivian Gómez: Universidad de los Andes; Pablo Figueroa: Universidad de los Andes; Kelly Katherine Peñaranda: Universidad de Los Andes,
C2148,Text2Gestures: A Transformer-Based Network for Generating Emotive Body Gestures for Virtual Agents,Uttaran Bhattacharya,uttaranb@umd.edu,"We present Text2Gestures, a transformer-based learning method to interactively generate emotive full-body gestures for virtual agents aligned with text inputs. Our method generates emotionally expressive gestures by utilizing the relevant affective features for body expressions. We train our network on the MPI Emotional Body Expressions Database and observe state-of-the-art performance in generating emotive gestures. We conduct a web-based user study and observe that around 91% of participants indicated our generated gestures to be at least plausible on a five-point Likert Scale. The emotions perceived by the participants from the gestures are also strongly positively correlated with the corresponding intended emotions.","Uttaran Bhattacharya: University of Maryland; Nick Rewkowski: University of Maryland; Abhishek Banerjee: University of Maryland, College Park; Pooja Guhan: University of Maryland College Park; Aniket Bera: University of Maryland at College Park; Dinesh Manocha: University of Maryland",
C2149,Augmented Reality based Surgical Navigation for Percutaneous Endoscopic Transforaminal Discectomy,Junjun Pan,pan_junjun@buaa.edu.cn,"Fluoroscopic guidance is a critical step for the puncture procedure in percutaneous endoscopic transforaminal discectomy (PETD). In this paper, we propose an AR surgical navigation system for PETD based on multi-modality imaging information, which contain fluoroscopy, optical tracking and depth camera. We also present a self-adaptive calibration and transformation method between 6-DOF optical tracking device and depth camera, which are in different coordinate systems. With substantially reduced frequency of fluoroscopy imaging, the system can accurately track and superimpose the virtual puncture needle on fluoroscopy images in real-time.",Junjun Pan: Beihang University; Ranyang Li: Beihang university; Dongfang Yu: State Key Laboratory of Virtual Reality Technology and Systems; Xinliang Wang: BUAA; Wenhao Zheng: Beihang University; Xin Huang: Peking University Third Hospital; Bin Zhu: Peking University Third Hospital; Haijun Zeng: Beijing Normal University; Xiaoguang Liu: Peking University Third Hospital,
C2151,Play with Emotional Characters: Improving User Emotional Experience by A Data-driven Approach in VR Volleyball Games,Zechen Bai,ustbbzch@gmail.com,"In real-world volleyball games, players are generally aware of the emotions of other players as they can observe facial expressions, body behaviors, etc., which evokes a rich emotional experience. However, most of the VR volleyball games mainly concentrate on modeling the game playing, rather than supporting an emotional experience. We introduce a data-driven framework to enhance the user's emotional experience and engagement by building emotional virtual characters in VR volleyball games. This framework enables virtual characters to arouse emotions according to the game state and express emotions through facial expressions. Evaluation results demonstrate our framework has benefits to enhance user's emotional experience and engagement.","Zechen Bai: Institute of Software, Chinese Academy of Sciences; Naiming Yao: Institute of Software, Chinese Academy of Sciences; Nidhi Mishra: Nanyang Technological University; Hui Chen: Institute of Software, Chinese Academy of Sciences; Hongan Wang: Institute of Software, Chinese Academy of Sciences; Nadia Magnenat Thalmann: Nanyang Technological University",
C2154,Bidirectional Shadow Rendering for Interactive Mixed 360° Videos,Danqing Dai,838370860@qq.com,"In this paper, we provide a bidirectional shadow rendering method to render shadows between real and virtual objects in the 360◦ videos in real time. We construct a 3D scene approximation from the current output viewpoint to approximate the real scene geometry nearby in the video. Then, we propose a ray casting based algorithm to determine the shadow regions on the virtual objects cast by the real objects. After that, we introduce an object-aware shadow mapping method to cast shadows from virtual objects to real objects. Finally, we use a shadow intensity estimation algorithm to determine the shadow intensity of virtual objects and real objects to obtain shadows consistent with the input 360◦ video.",Lili Wang: Beihang University; Hao Wang: Beihang University; Danqing Dai: Beihang University; Jiaye Leng: Beihang University; Xiaoguang Han: Shenzhen Research Institute of Big Data,
C2155,DSNet: Deep Shadow Network for Illumination Estimation,Yuan Xiong,xiongyuanxy@buaa.edu.cn,"Illumination consistency has applications to modeling and rendering in virtual reality. In 3D reconstruction and Mixed Reality(MR) fusion, the appearance of a large-scale outdoor scene may change frequently. The illumination inconsistency in photograph makes it challenging to fit to the existing model. To tackle this problem, this paper proposes a novel approach that can precisely estimate the illumination of the input image, and collaboratively utilizes illumination-based data augmentation for optimization. We show that illumination simulation can improve the performance of visual applications. Experimental results validate the effectiveness of the proposed approach, and show its superiority over the state-of-the-art.",Yuan Xiong: Beihang University; Hongrui Chen: Beihang University; Jingru Wang: Beihang University; Zhe Zhu: Duke University; Zhong Zhou: Beihang University,
C2156,VR-Phore: A Novel Virtual Reality system for Diagnosis of Binocular Vision,Sai Srinivas Vuddagiri,saisrinivas.vuddagiri@research.iiit.ac.in,"Binocular vision (BV) is the result of fusion between inputs from each eye to form a coherent image. BV anomalies are evaluated using different diagnostic tests and instruments. One such instrument is the Synoptophore, which evaluates three grades of BV. This equipment though efficient has certain limitations like ambient light while testing, bulky and expensive. We propose VR-Phore, application of a VR head-mounted display for diagnostics based on principle of the haploscope similar to Synoptophore. The proposed system addresses the limitations of Synoptophore with added advantage of a software platform to incorporate testing modules for a range of clinical conditions.",Sai Srinivas Vuddagiri: International Institute of Information Technology; Kavita Vemuri: International Institute of Information Technology - Hyderabad; MALE SHIVA RAM: University of Hyderabad; Rishi Bhardwaj: University of Hyderabad,
C2162,Effects of Language Familiarity in Simulated Natural Dialogue with a Virtual Crowd of Digital Humans on Emotion Contagion in Virtual Reality,Matias Volonte,mvolont@clemson.edu,"We compared the emotional impact caused by a crowd of affective virtual humans (VHs) that communicated in the users' native or foreign language. We evaluated the users' reactions to a crowd of VHs that exhibited distinct emotions: Positive, Negative, and Neutral. A Mixed condition included VHs showing Positive, Negative, and Neutral emotions. Users collected items from a digital market and interacted with the VHs using natural speech. Three language conditions included: one in the USA where participants interacted in English and two groups in Taiwan in English (foreign) or Mandarin (native). Findings revealed that language familiarity enhanced users’ emotions.",Matias Volonte: Clemson University; Chang Chun Wang: National Chiao Tung University; Elham Ebrahimi: UNC Wilmington; Yu Chun Hsu: Multimedia Engineering at National Chiao Tung University; Kuan-yu Liu: Multimedia Engineering at National Chiao Tung University; Sai-Keung Wong: National Chiao Tung University; Sabarish V. Babu: Clemson University,
C2163,Assessment of the Simulator Sickness Questionnaire for Omnidirectional Videos,Ashutosh Singla,ashutosh.singla@tu-ilmenau.de,"The SSQ is the most widely used questionnaire for the assessment of simulator sickness. Since the SSQ with its 16 questions was not designed for 360° video related studies, our research hypothesis in this paper was that it may be simplified to enable more efficient testing for 360° video. Hence, we evaluate the SSQ based on six different previously conducted studies. We derive reduced sets of questions using PCA for each test. Pearson Correlation is analysed to compare the relation of all obtained reduced questionnaires as well as two further variants of SSQ reported in the literature, namely VRSQ and CSQ. Our analysis suggests that with a minimum of 9 out of 16 questions yields a sufficient high agreement with the initial SSQ.",Ashutosh Singla: TU Ilmenau; Steve Göring: TU Ilmenau; Dominik Keller: TU Ilmenau; Rakesh Rao Ramachandra Rao: TU Ilmenau; Stephan Fremerey: TU Ilmenau; Alexander Raake: TU Ilmenau,
C2164,SuperPlane: 3D Plane Detection and Description from a Single Image,Weicai Ye,yeweicai@zju.edu.cn,"We present a novel end-to-end simultaneously plane detection and description network named SuperPlane to tackle the challenging conditions in matching problems. Through the applications in image-based localization and augmented reality, SuperPlane demonstrates the strong power of plane matching in the challenge scenarios.",Weicai Ye: Zhejiang University; Hai Li: Zhejiang University; Tianxiang Zhang: Beijing Institute of Spacecraft System Engineering; Xiaowei Zhou: Zhejiang University; Hujun Bao: Zhejiang University; Guofeng Zhang: Zhejiang University,
C2171,GazeTance Guidance: Gaze and Distance-Based Content Presentation for Virtual Museum,Haopeng Lu,luhp2018@sjtu.edu.cn,"The increasing popularity of virtual reality provides new opportunities for online exhibitions, especially for fragile artwork in museums. However, the limited guidance approaches of virtual museums might hinder the acquisition of knowledge. In this paper, a novel interaction concept is proposed named GazeTance Guidance, which leverages the user's gaze point and interact-distance towards the region of interest (ROI) and helps users appreciate artworks more organized. We conducted a series of comprehension tasks on several long scroll paintings and verified the necessity of guidance. Comparing with no-guidance mechanisms, participants showed a better memory performance on the ROIs without compromising presence and user experience.","Haopeng Lu: Shanghai Jiao Tong University; Huiwen Ren: Peking University; Yanan Feng: MIGU Co.,Ltd; Shanshe Wang: Peking University; Siwei Ma: Peking University; Wen Gao: Peking University",
C2172,Disocclusion Headlight for Selection Assistance in VR,Jianjun Chen,nefu_cjj@163.com,"We introduce the disocclusion headlight, a method for VR selection assistance based on alleviating occlusions at the center of the user's field of view. The user's visualization of the VE is modified to reduce overlap between objects. This way, selection candidate objects have larger image footprints, which facilitates selection. The modification is confined to the center of the frame, with continuity to the periphery of the frame which is rendered conventionally. We have tested our method on three selection tasks, where we compared it to the alpha cursor and the flower cone method. Our method showed significant advantages in terms of shorter task completion times, and of fewer selection errors.",Lili Wang: Beihang University; Jianjun Chen: Beihang University; Qixiang Ma: Beihang University; Voicu Popescu: Purdue University,
C2173,Stable Hand Pose Estimation under Tremor via Graph Neural Network,Zhiying Leng,zhiyingleng@buaa.edu.cn,"Hand pose estimation is a fundamental task in VR/AR applications. The tremor motion leads to estimations that deviate from user's intentions. We present a novel Graph Neural Network for stable hand pose estimation under tremor. Firstly, we propose the constraint adjacency matrix to mine the suitable graph topology, modeling spatial-temporal constraint of joints and outputting the precise 3D tremor hand pose. Then, we devise a tremor compensation module to obtain a stable hand pose, which exploits the constraint between control points and tremor hand pose. The extensive experiments show our method has achieved decent performance.",Zhiying Leng: Beihang University; Jiaying Chen: state key laboratory of virtual reality technology and systems; Hubert Shum: Durham University; Frederick Li: Durham University; Xiaohui Liang: Beihang University,
C2174,Effects of Virtual Environments and Self-representations on Redirected Jumping,Yi-Jun Li,yaoling@buaa.edu.cn,"We design experiments to measure the perception (detection thresh-olds for gains, presence, embodiment, intrinsic motivation, and cybersickness) and physical performance (heart rate intensity, preparation time, and actual jumping distance) of redirected jumping (RDJ), under six different combinations of virtual environments (VEs) (low and high visual richness) and self-representations (SRs) (invisible, shoes, human-like). Results suggested that both VEs and SRs influence users’ perception and performance in RDJ, and have to be taken into account when designing locomotion techniques.",Yi-Jun Li: Beihang University; Miao Wang: Beihang University; De-Rong Jin: Beihang University; Frank Steinicke: Universität Hamburg; Shi-Min Hu: Tsinghua University; Qinping Zhao: Beihang University,
C2181,Scene-Context-Aware Indoor Object Selection and Movement in VR,Ziming Ye,1440461523@qq.com,"VR applications such as interior design typically require accurate and efficient selection and movement of indoor objects. In this paper, we present an indoor object selection and movement approach by taking into account scene contexts such as object semantics and interrelations. This provides more intelligence and guidance to the interaction, and greatly enhances user experience. We evaluate our proposals by comparing them with traditional approaches in different interaction modes based on controller, head pose, and eye gaze. We demonstrate our findings via a furniture arrangement application.",Miao Wang: Beihang University; Ziming Ye: Beihang University; Jinchuan Shi: Beihang University; Yongliang Yang: University of Bath,
C2183,Cognitive Load/flow and Performance in Virtual Reality Simulation Training of Laparoscopic Surgery,Peng Yu,yupeng@buaa.edu.cn,"VR based laparoscopic surgical simulators (VRLS) are increasingly popular in training surgeons. However, they are validated by subjective methods in most research. In this paper, we resort to physiological approaches to objectively research quantitative influence and performance analysis of VRLS training system. The results show that the VRLS could highly improve medical students’ performance (p<0.01) and enable the participants to obtain flow experience with a lower cognitive load. The performance of participants is negatively correlated with cognitive load through quantitatively physiological analysis.",Peng Yu: Beihang University; Junjun Pan: Beihang University; Zhaoxue Wang: Beijing Normal University; Yang Shen: National Engineering Laboraory for Cyberlearning and Intelligent Technology，Faulty of education; Lili Wang: Beihang University; Jialun Li: Beihang University; Aimin Hao: Beihang University; Haipeng Wang: Beijing General Aerospace Hospital,
C2188,The Effects of a Stressful Physical Environment During Virtual Reality Height Exposure,Howe Yuan Zhu,howe.zhu@uts.edu.au,"Virtual reality height exposure is a reliable method of inducing stress with low variance across age and demographics. As the virtual environment's quality of rendering fidelity increases dramatically, it is leading to the neglect or simplification of the physical environment. This paper presents an experiment that explored the effects of an elevated physical platform with a virtually heightened environment to induce stress. Fifteen participants experienced four different conditions of varying physical and virtual heights. Participants reported significantly higher stress level when physically elevated regardless of the virtual height which suggests that the inherent elevation will induce more stress within participants.","Howe Yuan Zhu: University of Technology Sydney; Hsiang-Ting Chen: University of Adelaide; Chin-Teng Lin: Centre of Artificial Intelligence, School of Software, Faculty of Engineering and Information Technology, University of Technology Sydney",
C2199,"Capturing Human-Robot Interaction with Virtual Robots, Simulated Sensors, Real-Time Performance Capture, and Inverse Kinematics",Mark Murnane,mark25@umbc.edu,"We present a suite of tools to model a robot, its sensors, and the surrounding environment in VR, with the goal of collecting training data for real-world robots. The virtual robot observes a rigged avatar created in our photogrammetry facility and embodying a VR user. We are particularly interested in verbal human/robot interactions, which can be combined with the robot's sensor data for grounded language learning. Because virtual scenes, tasks, and robots are easily reconfigured compared to their physical analogs, our approach proves extremely versatile in preparing a wide range of robot scenarios for an array of use cases.","Mark Murnane: University of Maryland, Baltimore County; Padraig Higgins: University of Maryland, Baltimore County; Monali Saraf: University of Maryland, Baltimore County; Francis Ferraro: University of Maryland Baltimore County; Cynthia Matuszek: University of Maryland, Baltimore County; Don Engel: University of Maryland, Baltimore County",
C2200,VR-based Student Priming to Reduce Anxiety and Increase Cognitive Bandwidth,Mr Daniel Hawes,dhawes@toonrush.com,"Recent research indicates that many post-secondary students feel overwhelming anxiety, negatively impacting academic performance and overall well-being. In this paper, based on multidisciplinary literature analysis and innovative ideas in cognitive science, learning models, and emerging technologies, we introduce a theoretical framework that shows how and when priming activities can be introduced in the learning cycles to reduce anxiety and improve cognitive availability. This framework proposes a Virtual Reality based priming approach that uses games and meditative interventions. Our results show this approach's potential compared to no-priming scenarios for reducing anxiety and significance for VR gaming in improving cognitive bandwidth.",Daniel Hawes: Carleton University; Ali Arya: Carleton University,
C2204,Spatial Anchor Based Indoor Asset Tracking,Dr Mingze Xi,mingze.xi@csiro.au,"Indoor asset tracking is an essential task in many areas of industry, such as shipping and warehousing. Widely-used indoor asset tracking technologies are costly and typically require supporting infrastructure to communicate with active tags on the assets. This paper presents SABIAT, an indoor asset tracking technique for augmented reality (AR), that continuously tracks the approximate locations of an asset using spatial anchors and, when needed, the precise location of that asset using fiducial markers. We have applied our SABIAT technique to build a demonstrator system, AR-IPS, to show how assets can be tracked and located inside a large, multi-level building.",Wennan He: The Australian National University; Mingze Xi: CSIRO; Henry Gardner: The Australian National University; Ben Swift: Australian National University; Matt Adcock: CSIRO,
C2207,EncounteredLimbs: A Room-scale Encountered-type Haptic Presentation using Wearable Robotic Arms,Arata Horie,arata.horie@star.rcast.u-tokyo.ac.jp,"In this work, we present EncounteredLimbs; a novel, wearable approach to presenting a user with encountered-type haptic feedback. We realize this feedback using a wearable robotic limb that holds a plate where the user might interact with their room-scale environment. A technical evaluation of the implemented system showed that the system provides a stiffness over 25 N/m and slant angle errors under 3°. Three user studies show the limitations of haptic slant perception in humans and the quantitative and qualitative effectiveness of the current prototype system. We conclude the paper by discussing various potential applications and possible improvements that could be made to the system.",Arata Horie: The University of Tokyo; Mhd Yamen Saraiji: Keio University; Zendai Kashino: University of Tokyo; Masahiko Inami: University of Tokyo,
C2210,Work Surface Arrangement Optimization Driven by Human Activity,Jingjing Liu,m18627293699@163.com,"In this paper, we aim at guiding people to accomplish a personalized task, work surface organizing, in mixed reality environment. Through the cameras mounted in a MR device, e.g., Hololens, we firstly capture a person's daily activities in real scene when he uses the work surface. From such activities, we model the individual behavior habits and apply them to optimize the arrangement of the work surface. A cost function is defined for the optimization, considering general arrangement rules and human habitual behavior. The optimized arrangement is suggested to the user by augmenting the virtual arrangement on the real scene. To evaluate the effectiveness of our approach, we conducted experiments on a variety of scenes.",Jingjing Liu: Beijing Institude of Technology; Wei Liang: Beijing Institute of Technology; Bing Ning: Beijing Institute of Fashion Technology; Ting Mao: Beijing Institude of Technology,
C2211,Does Virtual Odor Representation Influence the Perception of Olfactory Intensity and Directionality in VR?,Wan-Lun Tsai,lookoutking@mislab.csie.ncku.edu.tw,"Visual stimuli have been proved to dominate human perception among multiple sensors in virtual environments. If visual stimuli can be used to guide the olfactory sense in VR, the design of the olfactory display can be simpler but still able to provide olfactory experience with more diversity. In this work, a portable olfactory display was proposed. An experimental study was conducted to investigate visual-olfactory human perception, i.e. how the visually virtual odor representation in VR influences human perception of real odor produced by the proposed olfactory display.",Shou-En Tsai: Department of Computer Science; Wan-Lun Tsai: National Cheng Kung University; Tse-Yu Pan: National Tsing Hua University; Chia-Ming Kuo: CityChaser; Min-Chun Hu: National Tsing Hua University,
C2216,Visual Complexity and Scene Recognition: How Low Can You Go?,Joshua Peter Handali,joshua.handali@uni.li,"Visual realism in Virtual Environments (VEs) increases immersion but also costs. As the extent of visual realism relates to the level of visual complexity, we investigate on the impact of visual complexity on users’ spatial orientation in a VE based on a real-world place. Visual complexity is varied by adding cartographic visual elements, namely a map overlay and 3D buildings, resulting in a 2x2 factorial within-participants study. Participants were asked to map their VE location to a real-world location. Our findings show that the addition of either visual element improved spatial orientation, while their combination only adds a slight improvement.",Joshua Peter Handali: University of Liechtenstein; Johannes Schneider: University of Liechtenstein; Michael Gau: Karlsruhe Institute of Technology; Valentin Holzwarth: University of Liechtenstein; Jan vom Brocke: University of Liechtenstein,
C2218,3D Fluid Volume Editing based on a Bidirectional Time Coupling Optimization Approach,Xiaoying Nie,niexy@buaa.edu.cn,"We propose a novel optimization approach to locally edit a 3D fluid volume. Starting from a fluid reconstruction sequence or a fluid simulation sequence, we formulate geometric deformations as a nonlinear optimization problem to match user-specified targets. To seamlessly blending the edited 3D fluid volume into an original temporal sequence, we provide a bidirectional time coupling optimization approach. This approach takes the physical properties of the previous frame and the next frame as constraints to solve the current frame and meanwhile respect the spatial-temporal consistency of editing in various scenarios. Our results indicate the intuitiveness and efficacy of our method.",Xiaoying Nie: Beihang University; Yong Hu: Beihang University; Zhiyuan Su: Beihang University; Xukun Shen: Beihang University,
C2220,Magnification Vision - a Novel Gaze-Directed User Interface,Prof Anthony Steed,a.steed@ucl.ac.uk,"We present a novel magnifying tool for virtual environments, whereusers are given a view of the world through a handheld windowcontrolled by their real-time eye gaze data. The system builds on theoptics of real magnifying glasses and prior work in gaze-directedinterfaces. A pilot study is run to evaluate these techniques againsta baseline, that reveals no significant improvement in performance,though users appear to prefer the new technique.",Sondre Agledahl: University College London; Anthony Steed: University College London,
C2223,Effect of Context and Distance Switching on Visual Performances in Augmented Reality,Mathilde Drouot,mathilde.drouot@imt-atlantique.fr,Augmented reality may lead the user to repeatedly look at different environments (real/virtual) and at different distances to process information. We studied how context and distance switching could (together or separately) affect users’ performances. 29 participants (16 video game players) performed two tasks that required to switch between two screens (visual search and target detection task). These screens could be virtual (using HoloLens2) or real and placed at 1.5 or 2 meters. Distance switching had an impact only on visual search performances. Participants’ levels of experience with video games modified the effect of context switching.,Mathilde Drouot: IMT Atlantique; LEBIGOT Nathalie: UBO; Jean-Louis de Bougrenet: IMT Atlantique; Vincent Nourrit: IMT Atlantique,
C2224,A VR/AR Environment for Multi-User Liver Anatomy Education,Danny Schott,danny.schott@ovgu.de,"We present a VR/AR multi-user prototype of a learning environment for liver anatomy education. Our system supports various learning scenarios, where users can participate in VR, AR, or via desktop PCs. A virtual organ library was created using nineteen liver datasets. As part of a user study with surgery lecturers (5) and medical students (5), we evaluated the usability and presence. A total of 435 individual statements were recorded and summarized to 49 statements. The results show that our prototype is usable, induces presence, and potentially support the teaching of liver anatomy and surgery in the future.",Danny Schott: Otto-von-Guericke University; Patrick Saalfeld: Otto-von-Guericke University; Gerd Schmidt: Otto-von-Guericke University; Fabian Joeres: Otto-von-Guericke University; Christian Boedecker: University Medicine of the Johannes Gutenberg-University; Florentine Huettl: University Medicine of the Johannes Gutenberg-University; Hauke Lang: University Medicine of the Johannes Gutenberg-University; Tobias Huber: University Medicine of the Johannes Gutenberg-University; Bernhard Preim: Otto-von-Guericke University; Christian Hansen: Otto-von-Guericke University,
C2227,WebPoseEstimator: A Fundamental and Flexible Pose Estimation Framework for Mobile Web AR,Yakun Huang,ykhuang@bupt.edu.cn,"Exploring immersive augmented reality (AR) on the cross-platform web has attracted a growing interest. We implement WebPoseEstimator, a fundamental and flexible pose estimation framework, running on the common web platform, and providing the core capability to enable true Web AR. WebPoseEstimator provides a first real-time pose estimation framework that optimizes the loosely coupled multi-sensor fusion framework to flexibly adapt heterogeneous mobile devices. We also introduce how to optimize and compile such computationally intensive pose estimation from C++ source code into JavaScript profiles of less than 2 MB, thus supporting the fundamental and underlying capability for implementing true Web AR.",Yakun Huang: Beijing University of Posts and Telecommunications; Xiuquan Qiao: Beijing University of Posts and Telecommunications; Zhijie Tan: Beijing University of Posts and Telecommunications; Jianwei Zhang: Capinfo Company Limited; Jiulin Li: Beijing National Speed Staking Oval Operation Company Limited,
C2232,Flashpen: A High-Fidelity and High-Precision Multi-Surface Pen for Virtual Reality,Hugo Romat,hugo.romat@gmail.com,"Digital pen interaction has become a first-class input modality for precision tasks such as writing, annotating, and drawing. In Virtual Reality, however, input is largely detected using cameras which does not nearly reach the fidelity we achieve with analog handwriting or the spatial resolution required to enable fine-grained on-surface input.
We present FlashPen, a digital pen for VR whose sensing principle affords accurately digitizing hand-writing and fine-grained 2D input for manipulation. We combine absolute camera tracking with relative motion sensing from an optical flow sensor. In this paper, we describe our prototype, a user study and several application prototypes.",Hugo Romat: ETH Zurich; Andreas Rene Fender: ETH; Manuel Meier: ETH Zürich; Christian Holz: ETH Zürich,
C2238,Virtual Morality: Using Virtual Reality to Study Moral Behavior in Extreme Accident Situations,Giulia Benvegnù,giulia.benvegnu@phd.unipd.it,"Virtual Reality (VR) has recently been employed to study moral dilemmas in driving contexts, in order to collect people’s preferences during unavoidable collisions and inform the design of Autonomous Vehicles (AVs). However, little is known about the experience of being the driver acting in such situations rather than being in an AV that chooses for you. We present a case study that uses VR to investigate emotional reactions and behavior in human and autonomous driving modes. Our findings showed increased arousal, negative valence, and perceived responsibility when participants faced moral dilemmas as drivers. Instead, in scenarios that did not involve killing someone, being in an AV was judged less pleasant than being the actual driver.",Giulia Benvegnù: University of Padova; Patrik Pluchino: University of Padova; Luciano Gamberini: University of Padova,
C2239,"The Impact of Avatar Appearance, Perspective and Context on Gait Variability and User Experience in Virtual Reality",Markus Wirth,markus.wirth@fau.de,"Gait supervision plays an important role in the diagnosis, analysis, and rehabilitation of motor impairments. In particular for rehabilitation, several applications in virtual reality (VR) exist showing similar outcomes like in vivo therapy. However, equivalence of underlying gait characteristics was not assessed so far. We analyzed the influence of different avatar appearances, environments, and perspectives on gait parameters in VR during different walking tasks.
Results show that gait stability is significantly impacted by VR exposure, walking tasks influence gait behavior differently in VR compared to in vivo, and thus equivalence of gait characteristics in VR may not be blindly assumed.",Markus Wirth: Friedrich-Alexander-Universität Erlangen-Nürnberg (FAU); Stefan Gradl: Friedrich-Alexander-Universität Erlangen-Nürnberg (FAU); Georg Felix Prosinger: Friedrich-Alexander-Universität Erlangen-Nürnberg (FAU); Felix Kluge: Friedrich-Alexander-Universität Erlangen-Nürnberg (FAU); Daniel Roth: Computer Aided Medical Procedures and Augmented Reality; Bjoern M Eskofier: Friedrich-Alexander-Universität Erlangen-Nürnberg,
C2242,Analysis of Positional Tracking Space Usage when using Teleportation,Eelke Folmer,efolmer@unr.edu,"Teleportation is a widely used virtual locomotion technique that allows users to navigate beyond the confines of available tracking space with a low possibility of inducing VR sickness. Because teleportation requires little physical effort and lets users traverse large distances instantly, a risk is that over time users might only use teleportation and abandon walking input. This paper provides insight into this risk by presenting results from a study that analyzes tracking space usage of three popular commercially available VR games that rely on teleportation. Our study confirms that positional tracking usage is limited by the use of teleportation.",Aniruddha Prithul: University of Nevada Reno; Eelke Folmer: University of Nevada,
C2245,Egocentric Distance Judgments in Full-Cue Video-See-Through VR Conditions are No Better than Distance Judgments to Targets in a Void,Koorosh Vaziri,vazir008@umn.edu,"We report the results of an experiment that provides new insight into the extent to which, and conditions under which, scene detail affects spatial perception accuracy in VR applications. Using a custom-built video-see-through HMD, participants judged distances in a real-world outdoor environment under three different conditions of detail reduction: raw camera view, Sobel-filtered camera view, and complete background subtraction, plus a control condition of unmediated real-world viewing. We found no significant difference in distance walked between the three VST conditions, despite significant differences in ratings of visual and experiential realism, suggesting a sole reliance on angular declination to the target, independent of context.",Koorosh Vaziri: University of Minnesota; Maria Bondy: University of Minnesota; Amanda Bui: University of Minnesota; Victoria Interrante: University of Minnesota,
C2250,Saw It or Triggered It : Exploring the Threshold of Implicit and Explicit Interaction for Eye-tracking Technique in Virtual Reality,Jing-Yuan Huang,niara7765@gmail.com,"With eye-tracking techniques, the virtual reality (VR) system can acquire what the user is looking at in the virtual environment (VE). In this paper, we tried to determine whether the eye-tracking techniques can be applied as implicit interactions. We conducted a user study to investigate the threshold of implicit and explicit interaction for the eye-tracking technique in VR. We designed three interfaces for users to judge whether they trigger objects in the VE when seeing them. The result provides a parameter in the design guideline, which brings a new VR storytelling technique.",Tzu-Hsuan Yang: Department of Computer Science & Information Engineering; Jing-Yuan Huang: Department of Computer Science & Information Engineerin; Ping-Hsuan Han: National Taipei University of Technology; Yi-Ping Hung: Department of Computer Science & Information Engineering,
C2253,Spherical World in Miniature: Exploring the Tiny Planets Metaphor for Discrete Locomotion in Virtual Reality,David Englmeier,david.englmeier@ifi.lmu.de,"We explore the concept of a Spherical World in Miniature (SWIM) for discrete locomotion in Virtual Reality (VR). A SWIM wraps a planar WIM around a physically embodied sphere. It thereby implements a tangible Tiny Planet metaphor that can be rotated and moved, enabling scrolling, scaling, and avatar teleportation. In a lab study (N=20), we compare the SWIM to a planar WIM using VR controllers. We test both concepts in a navigation task and also investigate the effects of two different screen sizes. Despite its less direct geometrical transformation, our results show that the SWIM performed superior in most evaluations.",David Englmeier: LMU Munich; Wanja Sajko: LMU Munich; Andreas Butz: LMU Munich,
C2254,Proximity Effect Correction for Fresnel Holograms on Nanophotonic Phased Arrays,Xuetong Sun,jedysun66@gmail.com,"The Nanophotonic Phased Array (NPA), a new type of holographic display, affords several advantages over other holographic display technologies. However, the thermal phase modulation of the NPA makes it susceptible to the thermal proximity effect where heating one pixel affects nearby pixels. Proximity effect correction (PEC) methods have been proposed for 2D Fourier holograms but not for Fresnel holograms at user-specified depths. We present a PEC method for the NPA for Fresnel holograms and validate it through simulations. Our method is not only effective in correcting the proximity effect of 2D images at desired depths but can also leverage the fast refresh rate of the NPA to display 3D scenes with time-division multiplexing.","Xuetong Sun: University of Maryland College Park; Yang Zhang Zhang: University of Maryland; Po-Chun Huang: University of Maryland; Niloy Acharjee: University of Maryland, College Park; Mario Dagenais: University of Maryland; Martin Peckerar: University of Maryland; Amitabh Varshney: University of Maryland College Park",
C2256,BouncyScreen: Physical Enhancement of Pseudo-Force Feedback,Yuki Onishi,yuki87@riec.tohoku.ac.jp,"We explore BouncyScreen, an actuated 1D display system that enriches indirect interaction with a virtual object by pseudo-haptic mechanism enhanced through the screen's physical movements. We configured a prototype of BouncyScreen with a flat-screen mounted on a mobile robot, which physically moves in accordance with the virtual object. Our weight discrimination study showed that BouncyScreen offers identical pseudo-force feedback to the vision-based pseudo-haptic technique. The results of the follow-up weight magnitude estimation study revealed different characteristics of a users' perceived weight magnitude depending on interaction styles and the enhancement of the reality of the interaction and the sense of presence.",Yuki Onishi: Tohoku University; Kazuki Takashima: Tohoku University; Kazuyuki Fujita: Tohoku University; Yoshifumi Kitamura: Tohoku University,
C2262,Using Fuzzy Logic to Involve Individual Differences for Predicting Cybersickness during VR Navigation,Yuyang Wang,yuyang.wang@ensam.eu,"Many studies show that individual differences affect users' susceptibility to cybersickness in VR. Based on the fuzzy logic theory, we developed a model to involve three individual differences (age, Gaming experience and ethnicity), and for validation, we correlated the corresponding outputs with the scores obtained from the simulator sickness questionnaire (SSQ) in a simple navigation scenario. Our work provides insights to establish customized experiences for VR navigation by involving individual differences.","Yuyang Wang: Arts et Métiers ParisTech; Jean-Rémy Chardonnet: Arts et Métiers, Institut Image; Frederic Merienne: Arts et Metiers; Jivka Ovtcharova: Karlsruhe Institute of Technology",
C2265,Personal Space Evaluation and Protection in Social VR,Chong Cao,chong@buaa.edu.cn,"Social VR has been widely promoted and popularized in recent years. Due to the immersion characteristic of VR, although people do not have physical contact in the virtual space, they still have judgement on distance and may feel annoyed when their personal space is intruded. Social VR users want to communicate with their virtual friends in the space, meanwhile keep a comfortable distance from other avatars and protect their personal space. In this paper, we evaluate user's perception and comfortable level of personal distance, and compare four different methods to protect personal space in social VR.",Jiayi Sun: Beihang University; Wenli Jiang: Beihang University; Lutong Li: School of New Media Art and Design; Chong Cao: Beihang University,
C2272,Visual Techniques to Reduce Cybersickness in Virtual Reality,Dr.-Ing. Susana Castillo,castillo@cg.cs.tu-bs.de,"Cybersickness is a unpleasant phenomenon caused by the visually induced impression of ego-motion while in fact being seated. To reduce its negative impact in VR experiences, we analyze the effectiveness of two techniques -- peripheral blurring and field of view reduction -- through an experiment in an interactive race game environment displayed with a commercial head-mounted display with integrated eye tracker. To measure the level of discomfort experienced by our participants, we utilize self-report and physiological measurements. Our results indicate that, among both techniques, reducing the displayed field of view up to 10 degrees is most efficient to mitigate cybersickness.",Colin Groth: TU Braunschweig; Jan-Philipp Tauscher: TU Braunschweig; Nikkel Heesen: TU Braunschweig; Susana Castillo: TU Braunschweig; Marcus Magnor: TU Braunschweig,
C2274,The Impact of Implicit and Explicit Feedback on Performance and Experience during VR-Supported Motor Rehabilitation,Negin Hamzeheinejad,negin.hamzeheinejad@stud-mail.uni-wuerzburg.de,"Patients with motor impairments may benefit greatly from sophisticated VR supported rehabilitation methods. However, it is crucial to investigate essential mechanisms that maximize the experience, performance, and therapy outcome. This paper examines the impact of explicit (visual and auditory cues and feedback) and implicit feedback (mirror neuron stimulation through the virtual trainer) on performance and user experience. Our results show that feedback improved the performance, objectively assessed by the applied support force of a gait robot. Additionally, VR improved enjoyment and satisfaction. Implicit feedback/adapted motion synchrony by the virtual trainer led to higher mental demand, indicating potentially increased neural activity.","Negin Hamzeheinejad: University of Würzburg, Department of Computer Science, HCI Group; Daniel Roth: Computer Aided Medical Procedures and Augmented Reality; Samantha Monty: Department of Computer Science, HCI Group; Julian Breuer: Neurologisches interdisziplinäres Behandlungszentrum; Anuschka Rodenberg: Neurologisches interdisziplinäres Behandlungszentrum; Marc Erich Latoschik: Department of Computer Science, HCI Group",
C2275,Adaptive Web-Based VR Streaming of Multi-LoD 3D Scenes via Author-Provided Relevance Scores,Hendrik Lievens,hendrik.lievens@uhasselt.be,"The growing storage requirements of 3D virtual scenes, and the increased heterogeneity of consumption devices trigger the need for
novel, on-demand streaming techniques of textured meshes. This paper proposes a way to perform adaptive bit-rate (ABR) scheduling using MPEG-DASH, tailored for VR consumption in the web browser. Scene authors are able to annotate the relative importance of assets to optimize scheduling decisions. The results show that Relevance ABR outperforms the state-of-the-art (measured using the MS-SSIM metric) across different scene complexities and network configurations, and is found to be most beneficial when scene complexity is high and network conditions are poor.",Hendrik Lievens: Hasselt University; Maarten Wijnants: Hasselt University; Mike Vandersanden: Hasselt University; Peter Quax: Hasselt University/Flanders Make/tUL; Wim Lamotte: Hasselt University,
C2278,Magnoramas: Magnifying Dioramas for Precise Annotations in Asymmetric 3D Teleconsultation,Kevin Yu,kevin.yu@tum.de,"We introduce Magnoramas, an interaction method for creating supernaturally precise annotations on virtual objects. We evaluated Magnoramas in a collaborative context in a simplified clinical scenario. Teleconsultation was performed between a remote expert inside a 3D reconstruction and embodied by an avatar in Virtual Reality that collaborated with a local user through Augmented Reality. The results show that Magnoramas significantly improve the precision of annotations while preserving usability and perceived presence measures compared to the baseline method. By additionally hiding the physical world while keeping the Magnorama, users can intentionally lower their perceived social presence and focus on their tasks.",Kevin Yu: Research Group MITI; Alexander Winkler: Technical University of Munich; Frieder Pankratz: LMU; Marc Lazarovici: Institut für Notfallmedizin; Prof. Dirk Wilhelm: Research Group MITI; Ulrich Eck: Computer Aided Medical Procedures and Augmented Reality; Daniel Roth: Computer Aided Medical Procedures and Augmented Reality; Nassir Navab: Technische Universität München,
C2279,Using Virtual Reality to Support Acting in Motion Capture with Differently Scaled Characters,Robin Kammerlander,robinkam@kth.se,"Motion capture is a well-established technology for capturing actors' performances within the entertainment industry. Instead of detailed sets, costumes and props, actors play in empty spaces wearing tight suits. Often, their co-actors are imaginary, replaced by placeholder props, or even out of scale with their virtual counterparts. We propose using a combination of virtual reality and motion capture technology to bring differently proportioned characters into a shared collaborative virtual environment. The results show that our proposed platform enhances actor’s feelings of body ownership and immersion, changing their performances, narrowing the gap between virtual performances and final intended animations.","Robin Kammerlander: Department of Speech, Music and Hearing; Andre Pereira: KTH Royal Institue of Technology; Simon Alexanderson: KTH Royal Institue of Technology",
C2282,Video Content Representation to Support the Hyper-reality Experience in Virtual Reality,HYERIM PARK,ilihot@kaist.ac.kr,"In this paper, we investigate a video content representation method to provide a hyper-reality experience of the narrative's world in virtual reality. We reflect the time and place settings of the video content in virtual reality and have participants watch the video in four different virtual reality environments. As a result, we reveal that reflecting the narratives' environment settings to the virtual reality environment significantly improves the spatial presence and narratives engagement. We also confirm a positive correlation between spatial presence and narrative engagement, including sub-scales such as emotional engagement and narrative presence.",HYERIM PARK: KAIST; Woontack Woo: KAIST,
C2285,Investigating Individual Differences in Olfactory Adaptation to Pulse Ejection Odor Display by Scaling Olfaction Sensitivity of Intensity,Shangyin Zou,zoushangyin@s.h.k.u-tokyo.ac.jp,"Olfactory adaptation is a non-negligible issue to consider to provide sustained olfaction experience in virtual reality. This study conducted experiments to measure users’ adaptation to pulse ejection odor display by ink-jet devices and analyzed the individual differences in olfactory perception. The results revealed that the average intensity perception dropped approximately to 70% of max perceived intensity in the 10-minute scent display session. Furthermore, individuals’ adaptation levels were correlated to personal sensitivity to olfactory intensity variations acquired by labeled magnitude scale. This work provided a theoretical basis to personalize odor display in VR for more stable olfactory experience.",Shangyin Zou: The University of Tokyo; Yuki Ban: The University of Tokyo; Shinichi Warisawa: The University of Tokyo,
C2287,Determining the Target Point of the Mid-Air Pinch Gesture,Reigo Ban,skysoyn@gmail.com,"Pinching is a common gesture primarily used for zooming on mobile devices, and previous studies considered utilizing it as a mid-air gesture in AR/VR. As opposed to touch screens, there is no physical contact point between the display and the fingers in mid-air pinching, which means the positional relationship between the target point for zooming and the users' finger movement in mid-air pinching could be different from that of touch screens. In this study, we investigated the relationship in mid-air pinching to estimate the target point from the hand posture, and found that the point was significantly off towards the thumb and away from the index finger (approximately 7% offset). This finding contributes to a more accurate mid-air zooming.",Reigo Ban: The University of Tokyo; Yutaro Hirao: The University of Tokyo; Takuji Narumi: the University of Tokyo,
C2292,Indicators and Predictors of the Suspension of Disbelief: Children's Individual Presence Tendencies,David Fernes,david.fernes@stud-mail.uni-wuerzburg.de,"Presence is a phenomenon where a person distributes his/her attention to internal (mental) or distal (sensory) cues. Research shows, that not only technological immersion, but also person-specific factors, influence the sense of presence. These factors may cause an individual presence tendency (IPT) that affects how presence is experienced. This paper investigates if an IPT exists, how it can be calculated, and what factors influence it. A study is presented with 78 participants, aged 13-16, who experienced three different environments within different immersive settings. The results show that level of technological immersion has a strong effect on presence.",Andreas Dengel: University of Würzburg; Lucas Plabst: Julius-Maximilians-University Würzburg; David Fernes: Julius-Maximilians University,
C2293,VR based Power Wheelchair Simulator: Usability Evaluation through a Clinically Validated Task with Regular Users,Guillaume Vailland,guillaume.vailland@irisa.fr,"Power wheelchairs are one of the main solutions for people with reduced mobility to maintain autonomy. However, safely driving a power wheelchair is a difficult task that requires training methods based on real-life situations often too complex to implement and unsuitable for some people with complex handicap. In this context, we developed a Virtual Reality based power wheelchair simulator. In this paper, we present a clinical study in which 29 power wheelchair regular users were asked to complete a driving task within two conditions: in virtual and in real life. The objective is to compare performances between the two conditions and to evaluate the Quality of Experience provided by our simulator.","Guillaume Vailland: INSA; Louise Devigne: INSA; Francois Pasteau: Univ Rennes, INSA; Florian Nouviale: Univ Rennes, INSA; Bastien Fraudet: Pôle Saint Hélier, rehabilitation center; Emilie Leblong: Pôle Saint Hélier, rehabilitation center; Marie Babel: Univ Rennes, INSA; Valérie Gouranton: Univ Rennes, INSA",
C2299,Who kicked the ball? Situated Visualization in On-Site Sports Spectating,Wei Hong Lo,wei.lo@postgrad.otago.ac.nz,"With the recent technological advancements in sports broadcasting, viewers that follow a sports game through broadcast media or online are presented with an enriched experience that includes additional content such as statistics and graphics that help to follow a game. In contrast, spectators at live sporting events often miss out on this additional content.  

In this paper, we explore the opportunities of using situated visualization to enrich on-site sports spectating. We developed two novel situated visualization approaches for on-site sports spectating: (1) situated broadcast-styled visualization which mimics television broadcasts and (2) situated infographics which places visual elements into the environment.",Wei Hong Lo: University of Otago; Stefanie Zollmann: University of Otago; Holger Regenbrecht: University of Otago,
C2308,Visualizing Planetary Spectroscopy through Immersive On-site Rendering,Lauren Gold,llgold@asu.edu,"Planetary Visor is our virtual reality tool to visualize orbital and rover-based datasets from the ongoing traverse of the NASA Curiosity rover in Gale Crater. Data from orbital spectrometers provide insight about the composition of planetary terrains. Meanwhile, Curiosity rover data provide fine-scaled localized information about Martian geology. By visualizing the intersection of the orbiting instrument's field of view with the rover-scale topography, and providing interactive navigation controls, Visor constitutes a platform for users to intuitively understand the scale and context of the Martian geologic data under scientific investigation.",Lauren Gold: Arizona State University; Alireza Bahremand: Arizona State University; Connor Richards: Arizona State University; Justin Hertzberg: Arizona State University; Kyle Sese: Arizona State University; Alexander A Gonzalez: Hamilton High School; Zoe Purcell: Arizona State University; Kathryn E Powell: Northern Arizona University; Robert LiKamWa: Arizona State University,
C2309,SHeF-WIP: Walking-in-Place based on Step Height and Frequency for Wider Range of Virtual Speed,Yutaro Hirao,hirao@cyber.t.u-tokyo.ac.jp,"Walking-in-place (WIP) approaches face difficulties in reaching high locomotion speeds because of the required high step frequency, rapidly creating an awkward or risky experience for the user. In this paper, we introduce a novel WIP approach called Step-Height-and-Frequency (SHeF) WIP, which considers a second parameter, i.e., the step height, in addition to the step frequency, to better control the speed of advancement. We compared SHeF-WIP with a conventional WIP system in a user study conducted with 12 participants. Our results suggest that SHeF-WIP enabled them to reach higher virtual speeds (+80%) with more efficacy and ease.",Yutaro Hirao: The University of Tokyo; Takuji Narumi: the University of Tokyo; Ferran Argelaguet Sanz: Inria; Anatole Lécuyer: Inria,
C2310,Gender Differences of Cognitive Loads in Augmented Reality-based Warehouse,Dr Xiangdong Li,axli@zju.edu.cn,"The rapid emergence of augmented reality (AR) has brought considerable advantages to contemporary warehouse. However, due to inherent biological and cognitive differences, the male and female workers perceive the AR systems differently. Understanding the differences is essential to improve workers’ productivity and well-being. Therefore, we developed the AR headset that helped the participants facilitate parcel scanning and evaluated the gender differences in context of long-lasting repetitive parcel scanning. The results show that the female workers had significantly lower operational efficiency, higher visual attention, and higher memory loads than the male, but they quickly gained advantages in these aspects.",Zihan Yan: Zhejiang University; Yifei Shan: Zhejiang University; Yiyang Li: Zhejiang University; Kailin Yin: Zhejiang University; Xiangdong Li: Zhejiang University,
C2311,Larger Step Faster Speed: Investigating Gesture-based Locomotion in Place with Different Walking Speed in Virtual Reality,Kening Zhu,kenju850915@gmail.com,"We investigated the technique of gesture-amplitude-based walking-speed control for locomotion in place (LIP) in VR. Study1 showed that compared to tapping and goose-stepping, the gesture of marching in place was preferred by users while sitting and standing. With the recorded data, we trained a classification model for LIP speed control based on users' leg/foot marching gestures. We then compared the marching-in-place speed-control technique with the controller-based teleportation approach on a target-reaching task. We found no significant difference between the two conditions in terms of accuracy. More importantly, the technique of marching in place yielded significantly higher user ratings in naturalness, realness, and engagement.",Pingchuan Ke: City University of Hong Kong; Kening Zhu: City University of Hong Kong,
C2313,Visual Indicators for Monitoring Students in a VR class,Yitoshee Rahman,yitoshee@gmail.com,"Remote classes using VR technology are gaining recognition when in-person meetings are difficult or risky. We designed an immersive VR interface with several visual cues to support teacher awareness of students and their actions, attention, and temperament in a social VR environment. This interface keeps relevant information about students within the teacher's visual field of attention and has options to reduce the amount of information presented. Pilot study participants preferred to see all student indicators in one place and suggested we minimize the amount of information displayed to focus on the most urgent students.",David Michael Broussard: University of Louisiana at Lafayette; Yitoshee Rahman: University of Louisiana at Lafayette; Arun K Kulshreshth: University of Louisiana at Lafayette; Christoph W Borst: University of Louisiana at Lafayette,
C2318,Velocity Guided Amplification of View Rotation for Seated VR Scene Exploration,Songhai Zhang,shz@tsinghua.edu.cn,"This paper presents a velocity guided amplification approach for head rotation in VR headsets, enabling the amplification factor tobe dynamically changed according to head rotation velocity, and keep it within the comfort range.  We first conducted experiments to investigate the effects of head rotation velocity on human sense towards the virtual view rotation and propose the velocity guided amplification approach. We then performed extensive evaluation by comparing our amplification method with existing linear mapping methods that use constant amplification factors. Results demonstrate that users achieve the best performance on given tasks with less discomfort when using our technique.",Songhai Zhang: Tsinghua University; Chen Wang: Tsinghua University; Yizhuo Zhang: Tsinghua University; Fang-Lue Zhang: Victoria University of Wellington; Nadia Pantidi: Victoria University of Wellington; Shi-Min Hu: Tsinghua University,
C2319,Walking Outside the Box: Estimation of Detection Thresholds for Non-Forward Steps,In-Kwon Lee,iklee@yonsei.ac.kr,"Redirected walking maps a virtual path and a real path with unnoticeable distortion for efficient space usage. To hide the distortion from the user, detection thresholds have been measured for forward steps. In addition to a forward step, adding a non-forward step can expand the VR locomotion in any direction. In this work, we measure the translation and curvature detection thresholds for non-forward steps. The results show similar translation thresholds with forward-step and wider thresholds for the curvature. Having non-forward steps in the redirected walking arsenal can add freedom to virtual world design and lead to efficient space usage.",Yong-Hun Cho: Yonsei University; Daehong Min: Yonsei University; Jin-Suk Huh: Yonsei University; Se-Hee Lee: Yonsei University; June-Seop Yoon: Yonsei University; In-Kwon Lee: Yonsei University,
C2323,Virtual Reality Based Mass Disaster Triage Training for Emergency Medical Services,Nicole Bilek BSc.,nicole.bilek@fhstp.ac.at,"When mass disasters with multiple casualties and injured people happen, the Emergency Medical Service staff needs to have strong organizational skills in addition to medical knowledge to efficiently apply triage systems. Currently, it is very expensive for Emergency Medical Services to practice these skills because they need to set up elaborate training scenarios with actors and complex environments. This work presents a Virtual Reality training application that aims to replicate the learning experience of the real-life training without the disadvantage of the organizational effort. The application complements the current training allowing for a more frequent training for all staff members.",Nicole Bilek BSc.: Institute for CreativeMedia/Technologies; Alisa Feldhofer: Institute for CreativeMediaTechnologies; Thomas Moser: Institute for CreativeMedia/Technologies,
C2329,An Embedded Virtual Experiment Environment System for Reality Classroom,Professor YanXiang Zhang,petrel@ustc.edu.cn,"We designed a low-cost augmented virtuality system based on the Oculus Quest to embed VR in classrooms. To build the system, we measure the size and position of tables in the classroom, make a proxy model in Unity, and then embed the proxy model to seamlessly within the real classroom. In this system, schoolchildren can realize collaborative experiments in ideal conditions or some hard-to-reach scenes. This system's contribution is: (1) By manually adding obstacles, it makes up for most VR systems that can only delimit the area but cannot identify obstacles. (2) It cleverly reuses tables and makes them play the role of anti-collision, workbench, and joystick placement. (3) It expands the available area of VR in complex environments.",YanXiang Zhang: University of Science and Technology of China; YuTong Zi: University of Science and Technology of China; JiaYu Wang: University of Science and Technology of China,
C2330,The Effect of Camera Height on The User Experience of Mid-air 360° VR Videos,Professor YanXiang Zhang,petrel@ustc.edu.cn,"Mid-air 360° videos are videos shot by placing the camera on the drone or helicopter. However, how the camera height of mid-air 360° videos affects user experience is unclear. The study explores whether the camera's height affects users' immersion, presence, and realism. Results suggest that when the camera height is higher, immersion decreases for acrophobic people while first drops and then rises for others because of the broad vision and beautiful scenery. Higher camera height brings a higher presence and worse realism, especially in distance details. Our work contributes to better understanding and designing of mid-air 360° video experiences.",YanXiang Zhang: University of Science and Technology of China; YingNa Wang: University of Science and Technology of China; BEIDOLLAHKHANI AZADEH: University of Science and Technology of China; Zheng Xi: University of Science and Technology of China,
C2331,Co-assemble- A collaborative AR cross-devices teaching system for assemble practice course,Professor YanXiang Zhang,petrel@ustc.edu.cn,"Assembly training in engineering drawing courses mainly relies on physical models, revealing many limitations. We use augmented reality and Azure Spatial Anchors to design “Co-assemble,” a multi-user cross-device collaborative system for the assembly practice on mobile devices. There are three modes in the system: single, collaboration, and class. The system will help students understanding the models’ structure and assembly activities and help teachers easily teach or monitor classes. We also presented and discussed the results of the preliminary user study evaluating the system.",YanXiang Zhang: University of Science and Technology of China; JiaQi Cheng: University of Science and Technology of China; JiaYu Wang: University of Science and Technology of China; Lei Zhao: University of Science and Technology of China,
C2334,Correction of Avatar Hand Movements Supports Learning of a Motor Skill,Klemen Lilija,lilija@di.ku.dk,"Learning to move the hands in particular ways is essential in many training and leisure virtual reality applications, yet challenging. Existing techniques that support learning of motor movement in virtual reality rely on external cues such as arrows showing where to move or transparent hands showing the target movement. We propose a technique where the avatar’s hand movement is corrected to be closer to the target movement. This embeds guidance in the user’s avatar, instead of in external cues and minimizes visual distraction. Through two experiments, we found that such movement guidance improves the short-term retention of the target movement when compared to a control condition without guidance.",Klemen Lilija: University of Copenhagen; Søren Kyllingsbæk: University of Copenhagen; Kasper Hornbæk: University of Copenhagen,
C2338,Virtual Reality Public Speaking Training: Experimental Evaluation of Direct Feedback Technology Acceptance,Fabrizio Palmas,fabriziopalmas@gmail.com,Virtual Reality Speech Training (VR-ST) helps trainees develop presentation skills and practice their application in the real world. Another benefit is direct feedback based on gamification principles. It is not yet clear if direct feedback is accepted by participants. We investigated how direct feedback in a VR-ST affects the participants' technology acceptance based on the Technology Acceptance Model (TAM). Our study compares a VR-ST with direct feedback (n=100) with a simulation-based VR-ST (n=100). The results show that direct feedback offers benefits to trainees by improving technology acceptance. Further results show that VR-ST is generally more accepted by participants without public speaking anxiety.,Fabrizio Palmas: Technical University Munich; Ramona Rainert: University of Augsburg; Jakub Edward Cichor: Technical University of Munich; David A. Plecher: Technical University; Gudrun Klinker: Technical University of Munich,
C2343,Towards Sneaking as a Playful Input Modality for Virtual Environments,Sebastian Cmentowski,sebastian.cmentowski@uni-due.de,"In our work, we explore the potential of sneaking as a playful input modality for virtual environments. Therefore, we discuss possible sneaking-based gameplay mechanisms and develop three technical approaches, including precise foot-tracking and two abstraction levels. Our evaluation reveals the potential of sneaking-based interactions in IVEs, offering unique challenges and thrilling gameplay. For these interactions, precise tracking of individual footsteps is unnecessary, as a more abstract approach focusing on the players' intention offers the same experience while providing better comprehensible feedback. Based on these findings, we discuss the broader potential and individual strengths of our gait-centered interactions.","Sebastian Cmentowski: University of Duisburg-Essen; Andrey Krekhov: University of Duisburg-Essen; André Zenner: Saarland University, Saarland Informatics Campus; Daniel Kucharski: University of Duisburg-Essen; Jens Krueger: University of Duisburg-Essen",
C2346,An Enhanced Photorealistic Immersive System using Augmented Situated Visualization within Virtual Reality,Maria Insa-Iglesias,maria.iglesias@gcu.ac.uk,"This work presents an This Enhanced Photorealistic Immersive system which allows image data and extracted features from a real-world location to be captured and modelled in a Virtual Reality environment combined with Augmented Situated Visualizations overlaid and registered in a virtual environment. Combining these technologies with techniques from Data Science and Artificial Intelligence allows the creation of a setting where remote locations can be modelled and interacted with from anywhere in the world. This system is adaptable to a wide range of use cases, although just a use case example focused on a structural examination of railway tunnels along with a pilot study is presented, which can demonstrate the usefulness of this system.",Maria Insa-Iglesias: Glasgow Caledonian University; Mark David Jenkins: Glasgow Caledonian University; Gordon Morison: Glasgow Caledonian University,
C2350,Matching 2D Image Patches and 3D Point Cloud Volumes by Learning Local Cross-domain Feature Descriptors,Weiquan Liu,wqliu1026@163.com,"Establishing the matching relationship of 2D images and 3D point clouds is a feasible solution to establish the spatial relationship between 2D space and 3D space. In this paper, we propose a novel network, 2D3D-GAN-Net, to learn the local invariant cross-domain feature descriptors of 2D image patches and 3D point cloud volumes. Then, the learned local invariant cross-domain feature descriptors are used for matching 2D images and 3D point clouds. Experiments show that the local cross-domain feature descriptors learned by 2D3D-GAN-Net are robust, and can be used for cross-dimensional retrieval on the 2D image patches and 3D point cloud volumes.",Weiquan Liu: Xiamen University; Baiqi Lai: Xiamen University; Cheng Wang: Xiamen University; Xuesheng Bian: Xiamen University; Chenglu Wen: Ximen University; Ming Cheng: Xiamen University; Yu Zang: Xiamen University; Yan Xia: Technical University of Munich; Jonathan Li: University of Waterloo,
C2357,A Novel Redirected Walking Algorithm for VR Navigation in Small Tracking Area,Dr Meng Qi,qimeng@sdnu.edu.cn,"We propose a novel steering algorithm for the RDW technique to direct users away from the boundary of the tracking area. During the navigation, we interactively and imperceptibly rotate the VE to make the user walking along arcs while thinking she is walking straightly. When the user is approaching the boundary, we hierarchically adjust the redirection gains to make the user turn away to avoid the reset procedure. The live-user study indicates that our algorithm can effectively speed up and smooth the navigation, reduce collisions and perceptual distortion, show the potential to direct multiple users simultaneously.",Meng Qi: Shandong Normal University; Yunqiu Liu: Shandong Normal University; JIA CUI: Shandong Normal University,
C2360,I Feel More Engaged When I Move!: Deep Learning-based Backward Movement Detection and its Application,Kyungsik Han,kyungsikhan@ajou.ac.kr,"We present the development of a prediction model for forward/backward movement while considering a user's orientation and the verification of the model's effectiveness. We built a deep learning-based model by collecting sensor data on the movement of the user's head, waist, and feet. We developed three realistic VR scenarios that involve backward movement, set three conditions (controller-based, treadmill-based, and model-based) for movement, and evaluated user experience in each condition through a study of 36 participants. The results of our study demonstrated that movement support through modeling is possible, suggesting its potential for use in many VR applications.",Seungwon Paik: Ajou University; Youngseung Jeon: Ajou University; Patrick C. Shih: Indiana University Bloomington; Kyungsik Han: Ajou University,
C2361,Evaluation of Body-centric Locomotion with Different Transfer Functions in Virtual Reality,BoYu Gao,boycegao@gmail.com,"Transfer functions are an important determinant of the locus of body centric locomotion methods. However, there is little known about the effects of transfer functions on virtual locomotion with different body parts. In this work, we selected four typical transfer functions and four common body parts from existing works, and conducted an experiment to evaluate their effects on virtual locomotion in VR. We presented the objective (task time, final position error and rate of failed trials) and subjective (user experience questionnaire-short) evaluation results. According to the results, we provide implications of designing body-centric locomotion with different transfer functions in VR.",BoYu Gao: Jinan University; Zijun Mai: Jinan University; Huawei Tu: La Trobe University; Henry Been-Lirn Duh: La Trobe University,
C2365,Subtle Gaze Guidance for 360° Content by Gradual Brightness Modulation and Termination of Modulation by Gaze Approaching,Masatoshi Yokomi,yokomi.masatoshi.yl7@is.naist.jp,"On VR, users do not always see the specific contents that the creators want them to focus on. For the creators to provide users with the immersive experience they intend, it is necessary to naturally guide the user's gaze to relevant spots in the virtual space. In this paper, we propose a subtle gaze guidance method for 360° content combining two techniques; gradual brightness modulation and termination of modulation by gaze approaching the guidance area. The experimental results show that our method significantly contributes to a more natural and less disturbing viewing experience while maintaining relatively high guidance performance.",Masatoshi Yokomi: Nara Institute of Science and Technology; Naoya Isoyama: Nara Institute of Science and Technology; Nobuchika Sakata: NAIST; Kiyoshi Kiyokawa: Nara Institute of Science and Technology,
C2370,StuckInSpace: Exploring the Difference Between Two Mediums of Play in a Multi-Modal Virtual Reality Game,Mr Yoan-Daniel Grigorov Malinov,ydgm1g16@soton.ac.uk,"Multi-modal co-located VR games are a very cost-effective way of adding a second or more players to the normally solitary VR experience. This paper introduces ""StuckInSpace"", a game used to test whether including a second player through a Phone or PC affects the immersion and co-presence of the participants. Quantitative data from the undertaken experiment shows that the mode does not affect the stated variables, while the qualitative data reveals why. Analyzing it gives a number of design decisions for future research in this field and shows that adding a second player this way is a viable method.",Yoan-Daniel Grigorov Malinov: University of Southampton; David Millard: University of Southampton; Tom Blount: University of Southampton,
C2371,The Impact of Virtual Reality and Viewpoints in Body Motion Based Drone Teleoperation,Matteo Macchini,matteo.macchini@gmail.com,"Operating telerobotic systems can be a challenging task. Body-Machine Interfaces represent a promising resource as they leverage intuitive body motion and gestures. Virtual Reality and first-person view perspectives can increase the user’s sense of presence in avatars, however, few studies concern the teleoperation of non-anthropomorphic robots. Our experiments on a non-anthropomorphic drone show that VR correlates with the spatial presence dimension, whereas viewpoints affect embodiment. Spontaneous body motion is affected by these conditions in terms of variability, amplitude, and robot correlates, suggesting that BoMIs for robotic teleoperation should carefully consider the use of VR and the choice of the viewpoint.",Matteo Macchini: EPFL; Manana Lortkipanidze: EPFL; Fabrizio Schiano: EPFL; Dario Floreano: EPFL,
C2379,TapID: Rapid Touch Interaction in Virtual Reality using Wearable Sensing,Manuel Meier,manuel.meier@inf.ethz.ch,"In this paper, we bring rapid touch interaction on surfaces to Virtual Reality. Current systems capture input with cameras to track controllers and hands in mid-air, but cannot detect touch input from the user. We present TapID, a wrist-based inertial sensing system to detect touch events on surfaces—the input modality common on phones and tablets. TapID reliably detects input events and identifies the finger used for touch, which we combine with optically tracked hand poses to trigger input in VR. We conclude with a series of applications that complement hand tracking with touch input.",Manuel Meier: ETH Zürich; Paul Streli: ETH Zürich; Andreas Rene Fender: ETH; Christian Holz: ETH Zürich,
C2384,Multiscale Sensor Fusion for Display-Centered Head Tracking,Tianyu Wu,tianyu_wu@ncsu.edu,"Emerging display usage scenarios require head tracking both at short (<1m) and modest (<3m) ranges. Yet it is difficult to find low-cost, unobtrusive tracking solutions that remain accurate across this range. By combining multiple head tracking solutions, we can mitigate the weaknesses of one solution with the strengths of another and improve head tracking overall. We built such a combination of two widely available and low-cost trackers, a Tobii Eye Tracker and a Kinect. The resulting system is more effective than Kinect at short range, and than the Tobii at a more distant range.",Tianyu Wu: NC State University; Benjamin Watson: NC State University,
C2386,Exploring Human-Computer Interaction (HCI) criteria in the design and assessment of Next Generation VR based education and training environments,J Cecil,j.cecil@okstate.edu,"This paper discusses the approach and outcomes of adopting design and assessment criteria based on Human-Computer Interaction (HCI) principles. A general framework is presented which has been adapted to support teaching and training in two domains: (i)  training of first responders involved in the Covid-19 and (ii) teach science and engineering to students with autism. The framework emphasizes the importance of HCI principles such as affordance, visual density, and cognitive load during the design process. The environments were created using various interfaces and immersion levels. The preliminary results of the assessment demonstrated positive impact of such environments for both domains.",J Cecil: Oklahoma State University; Sam O Kauffman: Oklahoma State University; Aaron Cecil-Xavier: University of Wisconsin-Madison; Avinash Gupta: Oklahoma State University; Vern McKinney: Yavapai Regional Medical Center; Mary Sweet-Darter: Applied Behavior Analysis of Oklahoma (ABA-OK),
C2391,Sensemaking Strategies with the Immersive Space to Think,Lee Lisle,llisle@vt.edu,"The process of sensemaking is a cognitively intensive task that involves foraging through and extracting information from large sets of documents. A recent approach, the Immersive Space to Think (IST), allows analysts to read, mark up documents, and use immersive 3D space to organize and label collections of documents. We observed seventeen novice analysts perform a sensemaking task in order to understand how users utilize the features of IST to extract meaning from large text-based datasets. We found three different layout strategies they employed to create meaning with the documents we provided, and found patterns of interaction and organization that can inform future improvements to the IST approach.",Lee Lisle: Virginia Tech; Kylie Davidson: Virginia Tech; Chris North: Virginia Tech; Doug Bowman: Virginia Tech; Edward J.K. Gitre: Virginia Tech,
C2392,Disturbance and Plausibility in a Virtual Rock Concert,Mel Slater,melslater@ub.edu,"A performance by the rock band Dire Straits was rendered in virtual reality, using computer vision techniques to extract the appearance and movements of the band from video, and crowd simulation for the audience. An online pilot study was conducted where participants experienced the scenario and freely wrote about their experience. The documents produced were analyzed using sentiment analysis. The results showed that some participants were disturbed by the accompanying virtual audience that surrounded them, while others enjoyed the performance. The results point to a profound level of Plausibility of the scenario in both cases.",Alejandro Beacco: Universitat de Barcelona; Ramon Oliva: Universitat de Barcelona; Carlos Cabreira: Universitat de Barcelona; Jaime Gallego: Universitat de Barcelona; Mel Slater: Universitat de Barcelona,
C2393,The Most Social Platform Ever? A Survey about Activities & Motives of Social VR Users,Philipp Sykownik,philipp.sykownik@uni-due.de,"We present online survey results on the activities and usage motives of social virtual reality users. We found that most users use social VR applications to satisfy diverse social needs. The second most frequently mentioned categories of activities and motives relate to experiential aspects such as entertainment activities. Another important category relates to the self, such as personal growth. Further, our results indicate that while social VR provides a superior social experience than traditional digital social spaces, users still have a desire for better and affordable tracking technology, increased sensory immersion, but also for further improvement concerning social features.",Philipp Sykownik: University of Duisburg-Essen; Linda Graf: University of Duisburg-Essen; Christoph Zils: University of Duisburg-Essen; Maic Masuch: University of Duisburg-Essen,
C2394,Text Selection in AR-HMD Using a Smartphone as an Input Device,Rajkumar Darbar,rajkumar.darbar@inria.fr,"Text selection is a common task while reading a PDF file or browsing the web. Efficient text selection techniques exist on desktops and touch devices, but are still under-explored for Augmented Reality Head Mounted Display (AR-HMD). Performing text selection in AR commonly uses hand-tracking, voice commands, and eye/head-gaze, which are cumbersome and lack precision. In this poster paper, we explore the use of a smartphone as an input device to support text selection in AR-HMD because of its availability, familiarity, and social acceptability. As an initial attempt, we propose four eyes-free, uni-manual text selection techniques for AR-HMD, all using a smartphone - continuous touch, discrete touch, spatial movement, and raycasting.",Rajkumar Darbar: INRIA Bordeaux; Joan Odicio-Vilchez: INRIA; Thibault Lainé: Asobo Studio; Arnaud Prouzeau: Monash University; Martin HACHET: Inria,
C2400,DreamStore: A Data Platform for Enabling Shared Augmented Reality,Meraj Ahmed Khan,khan.m.16@pg.com,"The natural mode of AR user-interaction triggers backend queries implicitly based on the field in the user's view at any instant, generating queries in excess of the device frame rate. Ensuring a smooth user experience in such a scenario requires a systemic solution exploiting the unique characteristics of the AR workloads. We propose DreamStore - a data platform that considers AR queries as first-class queries, and view-maintenance and large-scale analytics infrastructure around this design choice. Through performance experiments on large-scale and query-intensive AR workloads on DreamStore, we show the advantages and the capabilities of our proposed platform.",Meraj Ahmed Khan: The Procter & Gamble Company; Arnab Nandi: The Ohio State University,
C2401,VR-Spy: A Side-Channel Attack on Virtual Key-Logging in VR Headsets,Abdullah Al Arafat,abdullah.arafat@knights.ucf.edu,"In Virtual Reality, users typically interact with the virtual world using a virtual keyboard to access online accounts. Hence, it becomes imperative to understand the security of virtual keystrokes. In this paper, we present VR-Spy, a virtual keystrokes recognition method using WiFi signals. To the best of our knowledge, this is the first work that uses WiFi signals to recognize virtual keystrokes in VR headsets. VR-Spy leverages signal processing techniques to extract the patterns related to the keystrokes from the variations of WiFi signals. We implement VR-Spy using two Commercially Off-The-Shelf devices, a transmitter, and a receiver. Finally, VR-Spy achieves a virtual keystrokes recognition accuracy of 69.75%.",Abdullah Al Arafat: University of Central Florida; Zhishan Guo: University of Central Florida; Amro Awad: North Carolina State University,
C2403,Passing a Non-verbal Turing Test: Evaluating Gesture Animations Generated from Speech,Manuel Rebol,mrebol@american.edu,"We propose a data-driven technique for generating gestures directly from speech. Our approach is based on the application of Generative Adversarial Neural Networks (GANs) to model the correlation rather than causation between speech and gestures. This approach approximates neuroscience findings on how non-verbal communication and speech are correlated. 
We animate the generated gestures on a virtual character and evaluate the gestures in a user study. 
The study shows that users are not able to distinguish between the generated and the recorded gestures.
Moreover, users are able to identify our synthesized gestures as related or not related to a given utterance.",Manuel Rebol: American University; Christian Gütl: Graz University of Technology; Krzysztof Pietroszek: American University,
C2406,VXSlate: Combining Head Movement and Mobile Touch for Large Virtual Display Interaction,Khanh-Duy Le,duy.le@se.abb.com,"Virtual reality (VR) can open opportunities for users to accomplish complex tasks on large virtual displays using compact setups. However, interacting with large virtual displays using existing interaction techniques might cause fatigue, especially for precise manipulations, due to the lack of physical surfaces.  We designed VXSlate, an interaction technique that uses a large virtual display as an expansion of a tablet. VXSlate combines a user’s head movements as tracked by the VR headset, and touch interaction on the tablet. The user head movements position both a virtual representation of the tablet and of the user's hand on the large virtual display.The user’s multi-touch interactions perform finely-tuned content manipulations.",Khanh-Duy Le: ABB Corporate Research; Tanh Quang Tran: University of Otago; Karol Chlasta: Polish-Japanese Academy of Information Technology; Krzysztof Krejtz: SWPS University of Social Sciences and Humanities; Morten Fjeld: Chalmers University of Technology; Andreas Kunz: ETH Zurich,
C2410,Head Up Visualization of Spatial Sound Sources in Virtual Reality for Deaf and Hard-of-Hearing People,Mohammadreza Mirzaei,mohammad.mirzaei@tuwien.ac.at,"This paper presents a novel method for the visualization of 3D spatial sounds in Virtual Reality (VR) for Deaf and Hard-of-Hearing (DHH) people. Our method enhances traditional VR devices with additional haptic and visual feedback, which aids spatial sound localization. The proposed system automatically analyses 3D sound from VR application, and it indicates the direction of sound sources to a user by two Vibro-motors and two Light-Emitting Diodes (LEDs). Our study results suggest that DHH participants could complete sound-related VR tasks significantly faster using LED and haptic+LED conditions in comparison to only haptic feedback.",Mohammadreza Mirzaei: Vienna University of Technology; Peter Kán: Vienna University of Technology; Hannes Kaufmann: Vienna University of Technology,
C2414,Multi-modal Spatial Object Localization in Virtual Reality for Deaf and Hard-of-Hearing People,Mohammadreza Mirzaei,mohammad.mirzaei@tuwien.ac.at,"In this paper, we propose a novel Omni-directional particle visualization method and evaluate multi-modal presentation methods in Virtual Reality (VR) for Deaf and Hard-of-Hearing (DHH) persons, such as audio, visual, haptic, and a combination of them (AVH). Additionally, we compare the results with the results of hearing persons. Our user studies show that both DHH and hearing persons could do VR tasks significantly faster using AVH. Also, we found that DHH persons can do visual-related VR tasks faster than hearing persons by using our new proposed visualization method. Our qualitative and quantitative evaluation indicates that both participants preferred AVH method.",Mohammadreza Mirzaei: Vienna University of Technology; Peter Kán: Vienna University of Technology; Hannes Kaufmann: Vienna University of Technology,
C2421,Exploiting Object-of-Interest Information to Understand Attention in VR Classrooms,Efe Bozkir,efe.bozkir@uni-tuebingen.de,"Developments in computer graphics and hardware technology enable easy access to VR headsets. The immersion provided by VR may soon help to create realistic digital alternatives to conventional classrooms. Until now, however, students' behaviors in immersive virtual environments have not been investigated in depth. This work studies students' attention by exploiting object-of-interests using eye tracking in different classroom manipulations, particularly sitting positions of students, visualization styles of avatars, and various hand-raising behaviors of peer-learners. We show that such manipulations affect students' attention. Our research may contribute to understanding how visual attention relates to social dynamics in virtual classrooms.",Efe Bozkir: University of Tübingen; Philipp Stark: University of Tübingen; Hong Gao: University of Tübingen; Lisa Hasenbein: University of Tübingen; Jens-Uwe Hahn: Hochschule der Medien Stuttgart; Enkelejda Kasneci: University of Tübingen; Richard Göllner: University of Tübingen,
C2423,2-Thumbs Typing:A Novel Bimanual Text Entry Method  in Virtual Reality Environments,Minghui Sun,smh@jlu.edu.cn,"We propose a new technique named 2-Thumbs Typing (2TT) enabling text entry with a touchpad in HTC VIVE controller using two thumbs. 2TT method works similarly with bimanual handwriting input but using new designed uni-stroke gestures considering only strokes’ direction. We first design a set of gestures and improve them to finish the final design by a preliminary study through memory, performance efficiency and ease of use. The initial results show that the 2TT technique is easy and comfortable to use, no additional equipment required and supporting eyes-free entry. 2TT can reach 8.5 words per minute with extensive training.",Zigang Zhang: College of Software; Minghui Sun: Jilin University; BoYu Gao: Jinan University; Limin Wang: Jilin University,
C2427,Empirically Evaluating the Effects of Perceptual Information Channels on Size Perception of Tangibles in Near-field Virtual Reality,Alexandre Gomes de Siqueira,agomesdesiqueira@ufl.edu,"The success of applications combining tangibles and VR often depends on how accurately size is perceived. Research has shown that visuo-haptic perceptual information is important in size perception.  However, it is unclear how these sensory-perceptual channels are affected by immersive virtual environments that incorporate tangibles. We conducted a between-subjects study evaluating the accuracy of size perception across three experimental conditions (Vision-only, Haptics-only, Vision and Haptics). Overall, participants consistently over-estimated the size of dials regardless of the type of perceptual information. Our results also revealed an increased efficiency in reporting size over time most pronounced in the visuo-haptic condition.",Alexandre Gomes de Siqueira: University of Florida; Rohith Venkatakrishnan: Clemson University; Roshan Venkatakrishnan: Clemson University; Ayush Bhargava: Key Lime Interactive; Kathryn Lucaites: Clemson University; Hannah Solini: Clemson University; Moloud Nasiri: Clemson University; Andrew Robb: Clemson University; Christopher Pagano: Clemson University; Brygg Ullmer: Clemson University; Sabarish V. Babu: Clemson University,
C2429,"Mobile, Egocentric Human Body Motion Reconstruction Using Only Eyeglasses-mounted Cameras and a Few Body-worn Inertial Sensors",Young-Woon Cha,youngcha@cs.unc.edu,"We envision a convenient telepresence system available to users anywhere, anytime, requiring displays and sensors embedded in commonly worn items such as eyeglasses, wristwatches, and shoes. To that end, we present a standalone real-time system for the dynamic 3D capture of a person, relying only on cameras embedded into a head-worn device, and on Inertial Measurement Units (IMUs) worn on the wrists and ankles. We demonstrate our system by reconstructing various human body movements. We captured an egocentric visual-inertial 3D human pose dataset, which we plan to make publicly available for training and evaluating similar methods.",Young-Woon Cha: University of North Carolina at Chapel Hill; Husam Shaik: University of North Carolina at Chapel Hill; Qian Zhang: University of North Carolina at Chapel Hill; Fan Feng: University of North Carolina at Chapel Hill; Andrei State: University of North Carolina at Chapel Hill; Adrian Ilie: University of North Carolina at Chapel Hill; Henry Fuchs: UNC Chapel Hill,
C2446,Dynamic Density-based Redirected Walking Towards Multi-user Virtual Environments,Dr. Tianyang Dong,dty@zjut.edu.cn,"The boundary conflicts in the real walking for multi-user VR applications is related to the density of users in physical space. In order to decrease the boundary conflicts, this paper presents a novel method of dynamic density-based redirected walking towards multi-user virtual environments. The method dynamically adjusts the user distribution to the desired state with high center density and low boundary density through the density force, which is generated by the density difference between standard density and actual density. The experiment results show that our method can reduces the conflicts about 30% compared with other existing multi-user redirected walking methods.",Tianyang Dong: Zhejiang University of Technology; Yue Shen: Zhejiang University of Technology; Tieqi Gao: Zhejiang University of Technology; Jing Fan: Zhejiang University of Technology,
C2448,TeleGate: Immersive Multi-User Collaboration for Mixed Reality 360° Video,Jacob Young,jacobyoung.research@gmail.com,"When collaborating on virtual content within 360° mixed reality environments
it is often desirable for collaborators to fully immerse themselves
within the task space, usually by means of a head-mounted
display. However, these socially isolate any co-located collaborators,
removing the ability to communicate through important gestural,
facial, and body language cues. We present TeleGate, a system that instead utilises a shared immersive display to allow collaboration within remote environments between an arbitrary number of users, keeping collaborators visible while allowing immersive and interactive collaboration within remote environments.",Hyejin Kim: Victoria University of Wellington; Jacob Young: Victoria University of Wellington; Daniel Medeiros: University of Glasgow; Stephen Thompson: Victoria University of Wellington; Taehyun James Rhee: Victoria University of Wellington,
C2453,Evaluation of Curved Raycasting-based Interactive Surfaces in Virtual Environments,Technical Expert Tomomi Takashina,tomomi.takashina@nikon.com,"As 3D user interfaces become more popular, quick and reliable aerial
selection and manipulation are desired.  We evaluated a virtual curved
interactive surface with controllable curvature based on raycasting.
To investigate the users’ operation ability for different
curved conditions, we experimented with multiple surface curvature
radii, including completely flat conditions. The experimental results
showed that varying the curvature of the display improved the pointing
accuracy by 28% and the speed by 15% over the flat surface in the most
effective cases. These findings can be applied to curved interactive
surfaces with mid-air pointing for 2D-style applications.",Tomomi Takashina: Nikon Corporation; Mitsuru Ito: Nikon Corporation; Hitoshi Nagaura: Nikon Systems Inc.; Eisuke Wakabayashi: Nikon Systems Inc.,
C2455,Comparative Evaluation of Digital Writing and Art in Real and Immersive Virtual Environments,Roshan Venkatakrishnan,rvenkat@g.clemson.edu,"With Virtual Reality increasingly being applied in educational contexts where writing and note taking is crucial, it is important to study how well humans can perform these tasks in VR. In a between-subjects evaluation, we studied participants' fine motor coordination in real and virtual settings, further examining the effects of providing a virtual self avatar on task performance.  Overall, it appears that while writing and artistic activities can be successfully supported in VR applications using specialized input devices, the accuracy in performing such tasks is compromised, highlighting the need for developments that support such fine motor tasks in VR.",Roshan Venkatakrishnan: Clemson University; Rohith Venkatakrishnan: Clemson University; Sabarish V. Babu: Clemson University; Yu-Shuen Wang: National Chiao Tung University,
C2461,The Effects of Cognitive Load on Engagement in a Virtual Reality Learning Environment,Jhon Bueno Vesga,jab55d@mail.missouri.edu,"Engagement has been traditionally linked to presence in desktop-based virtual reality learning environments. The main purpose of this study was to explain if individual dimensions of cognitive load (mental demand, effort, and frustration level) can be used in addition to factors like presence and self-efficacy to predict student’s cognitive engagement. The results of the study confirmed presence and self-efficacy as significant predictors of student’s engagement. Also, a three-step hierarchical regression analysis revealed that two of the three individual dimensions of cognitive load (effort and frustration level) were also significant predictors of student’s engagement.",Jhon Bueno Vesga: University of Missouri; Xinhao Xu: University of Missouri; Hao He: University of Missouri,
C2462,Adjusting Relative Translation Gains According to Space Size in Redirected Walking for Mixed Reality Mutual Space Generation,Dooyoung Kim,banana8881@kaist.ac.kr,"We propose the concept of relative translation gains, a novel Redirected Walking (RDW) method to create a mutual movable space between the Augmented Reality (AR) host's reference space and the Virtual Reality (VR) client's space. Our method adjust the remote client's walking speed for each axis of a VR space to modify the movable area without coordinate distortion. We estimate the relative translation gain threshold according to reference space size. Our study showed that for remote clients connected to the larger reference space, relative translation gains can be increased to utilize a VR space bigger than their real space.",Dooyoung Kim: KAIST; Jae-eun Shin: KAIST; Jeongmi Lee: KAIST; Woontack Woo: KAIST,
C2487,Exploring Input Approximations for Control Panels in Virtual Reality,Markus Tatzgern,markus.tatzgern@fh-salzburg.ac.at,"We present an exploration of hand input approximations of real hands to manipulate the buttons, toggles, knobs and sliders using typical handheld VR controllers. We use Oculus Quest controllers that rely on capacitive sensing to create basic, approximate hand gestures. We demonstrate the potential of our designs by comparing approximate hand gestures against using the controller's joystick that allows fine motor thumb input, and a baseline ray-casting interaction. A detailed analysis of our interaction designs using the Framework for Interactive Fidelity Analysis (FIFA)  allows us to discuss differences between input approximations and the real-world hand manipulations.",Markus Tatzgern: Salzburg University of Applied Sciences; Christoph Birgmann: Salzburg University of Applied Sciences,
C2491,Gaze-Pinch Menu: Performing Multiple Interactions Concurrently in Mixed Reality,Yaguang Lu,luyaguang@buaa.edu.cn,"Performing an interaction using gaze and pinch has been certified as an efficient interactive method in Mixed Reality, for such techniques can provide users concise and natural experiences. However, executing a task with individual interactions gradually is inefficient in some application scenarios. In this paper, we propose the Hand-Pinch Menu, which core concept is to reduce unnecessary operations by combining several interactions. Users can continuously perform multiple interactions on a selected object concurrently without changing gestures by using this technique. The user study results show that our Gaze-Pinch Menu can improve operational efficiency effectively.",Yaguang Lu: Beihang University; Xukun Shen: Beihang University; Huiyan Feng: Beihang University; Pengshuai Duan: Beihang University; Shijin Zhang: Beihang University; Yong Hu: Beihang University,
C2492,MagicCube: A One-Handed Interaction Approach in 3D Environment on Smartphones,Mengyuan Wang,jyjy1@qq.com,"When users have only one free hand to operate smartphones, interaction with 3D virtual environment(VE) is restricted. We propose MagicCube, a cube with 5 DOF that perfectly integrates navigation and selection in 3D VE, to address this problem. Three sets of opposing faces are assigned to feature faces with translation, rotation, and selection. All operations can be performed by dragging the corresponding face. Further, by rotating the cube, users can choose the displayed faces and adjust their relative position according to their preference. A comparative analysis showed that it could effectively reduce the finger’s visual occlusion as well as improve the accuracy and stability of interaction operations.",Mengyuan Wang: Beihang University; Yong Hu: Beihang University; Chuchen Li: Beihang University; Xukun Shen: Beihang University,
C2494,A Preliminary Investigation of Avatar Use in Video-Conferencing,Mr Darragh Higgins,higgind3@tcd.ie,"Avatar use on video-conference platforms has found dual purpose in recent times as a potential method for ensuring privacy and improving subjective engagement with remote meeting, provided one can also ensure a minimal loss in the quality of social interaction and sense of personal presence. This preliminary study focuses on interaction through virtual avatars in a video conferencing context",Darragh Higgins: Trinity College; Rachel McDonnell: Trinity College Dublin,
C2498,Camera Space Synthesis of Motion Effects Emphasizing a Moving Object in 4D films,Sangyoon Han,han0209@postech.ac.kr,"One of the most frequent effects in four-dimensional (4D) films is the object-based motion effect, which refers to the vestibular stimulus generated by a motion chair to emphasize a moving object of interest displayed on the screen. This paper presents an algorithm for synthesizing convincing object-based motion effects automatically from a given object motion trajectory. Our method creates motion effects that simultaneously express the translation and rotation of an object in the motion platform’s limited workspace and DoFs while considering visual perception. The experimental results indicate that our method can generate compelling object-based motion effects that better enhance the 4D film viewing experience than the previous methods.",Sangyoon Han: Pohang University of Science and Technology (POSTECH); Gyeore Yun: POSTECH; Seungmoon Choi: Pohang University of Science and Technology (POSTECH),
C2501,Don’t Worry be Happy - Using virtual environments to induce emotional states measured by subjective scales and heart rate parameters,Tanja Kojic,tanja.kojic@tu-berlin.de,"Advancing technology and higher availability of Virtual Reality (VR) devices sparked its application in various research fields. For instance, health-related research showed that simulated nature environments in VR could reduce arousal and increase valence levels. This study investigates how the amount of possible interactivity influences the presence in nature environments and consequences on arousal and valence.
After inducing fear (high arousal and low valence) through a VR-horror game, it was tested how participants recovered if they played a VR-nature game with either no, limited, or extensive interaction.
The horror game proved to be a valid stimulus for inducing high arousal and low valence with a successful manipulation check.",Jan-Niklas Voigt-Antons: Technische Universität Berlin; Robert Spang: Technische Universität Berlin; Tanja Kojic: Technische Universität Berlin; Luis Meier: Technische Universität Berlin; Maurizio Vergari: Technische Universität Berlin; Sebastian Möller: Technische Universität Berlin,
C2507,Who Are Virtual Reality Headset Owners? A Survey and Comparison of Headset Owners and Non-Owners,Jonathan Kelly,jonkelly@iastate.edu,"Researchers can readily recruit head-mounted display (HMD) owners to participate remotely. However, HMD owners recruited online may differ from the university community that typically participates in virtual reality research. HMD owners (n=220) and non-owners (n=282) were surveyed through two online work sites and an undergraduate pool. Participants completed demographics and measures of HMD use, video game use, spatial ability, and motion sickness. In the context of the populations sampled, the results provide a characterization of HMD owners, a snapshot of commonly owned HMDs, a comparison between owners and non-owners, and a comparison among online workers and undergraduates.",Jonathan Kelly: Iowa State University; Lucia Cherep: Iowa State University; Alex Lim: Iowa State University; Taylor A Doty: Iowa State University; Stephen B. Gilbert: Iowa State University,
C2510,Field of View Effect on Distance Perception in Virtual Reality,Sina Masnadi,sina@knights.ucf.edu,"Recent state-of-the-art Virtual Reality HMDs provide wide FoV which were not possible in the past. Previous efforts have shown that reduced FoVs affect user perception of distance in a given environment, but none have investigated VR HMDs with wide FoVs. In this paper, we directly investigate the effect of HMD FoV on distance estimation in virtual environments. We performed a user study with 14 participants who performed a blind throwing task wearing a Pimax 5K Plus HMD, in which we virtually restricted the FoV to 200, 110, and 60 degrees. We found a significant difference in perceived distance between the 200 and 60 FoVs, as well as between the 110 and 60 FoVs. However, no significant difference was observed between 200 and 110 degrees.",Sina Masnadi: University of Central Florida; Kevin Pfeil: University of Central Florida; Jose-Valentin T Sera-Josef: University of Central Florida; Joseph LaViola: University of Central Florida,
C2514,MagicChem: A Multi-modal Mixed Reality System Based on Needs Theory for Chemical Education,Tianren Luo,784587107@qq.com,"MR technology provides us with the possibility of solving the safety issues and the space-time constraints, while the theory of human needs provides us with a way to think about designing a comfortable and stimulant MR system with realistic visual presentation and interaction. This study combines with the theory of human needs to propose a new needs model for virtual experiment. Based on this needs model, we design and develop a comprehensive MR system called MagicChem to verify the needs model. User study shows MagicChem that satisfies the needs model is better than the MR experimental environment that partially meet the needs model. In addition, we explore the application of the needs model in VR environment.",Tianren Luo: Research Institute of Virtual Reality and Intelligent System; Ning Cai: Research Institute of VR&IS; Zheng Li: Research Institute of VR&IS; Jinda Miao: College of computer science; Zhipeng Pan: Research Institute of VR&IS; YuZe Shen: Research Institute of VR&IS; Zhigeng Pan: Hangzhou Normal University; Mingmin Zhang: College of computer science,
C2519,Influence of Interactivity and Social Environments on User Experience and Social Acceptability in Virtual Reality,Maurizio Vergari,maurizio.vergari@tu-berlin.de,"Nowadays, Virtual Reality (VR) technology can be potentially used everywhere. Nevertheless, it is still uncommon to see VR devices in public settings. In these contexts, unaware bystanders in the surroundings might influence the User Experience (UX) and create concerns about the social acceptability of this technology. This paper investigates the influence of Social Environments, and degree of interactivity on User Experience and social acceptability. Four Social Environments were simulated employing 360° Videos, and two VR games developed with two levels of interactivity. Findings indicate that Social Environments and degree of interactivity should be taken into account while designing VR applications.",Maurizio Vergari: Technische Universität Berlin; Tanja Kojic: Technische Universität Berlin; Francesco Vona: Politecnico di Milano; Franca Garzotto: Politecnico di Milano; Sebastian Möller: Technische Universität Berlin; Jan-Niklas Voigt-Antons: Technische Universität Berlin,
C2520,HMD Type and Spatial Ability: Effects on the Experiences and Learning of Students in Immersive Virtual Field Trips,Dr. pejman sajjadi,sfs5919@psu.edu,"We report on the results of a study in the context of place-based immersive VR (iVR) geoscience education that compares the experiences and learning of 45 students after going through an immersive virtual field trip, using either a lower-sensing but scalable Oculus Quest or a higher-sensing but tethered HTC Vive Pro. Our results suggest that with content design considerations, standalone HMDs can be a viable replacement for high-end ones in large-scale educational studies. Furthermore, our results also suggest that the spatial ability of students can be a determining factor for their experiences and learning.",pejman sajjadi: Pennsylvania State University; Jiayan Zhao: The Pennsylvania State University; Jan Oliver Wallgrün: The Pennsylvania State University; Peter LaFemina: The Pennsylvania State University; Alexander Klippel: The Pennsylvania State University,
C2526,Inspiring healthy Food Choices in a Virtual Reality Supermarket by adding a tangible Dimension in the Form of an Augmented Virtuality Smartphone,Christian Eichhorn,christian.eichhorn@tum.de,"We want to understand the changing shopping behavior, influenced by health-targeting nutrition apps on mobile devices. On top of that, we built a virtual replica smartphone in VR with nutrition-related functionality. This has been extended with an Augmented Virtuality (AV) feature, that enables us to track the screen of a participant’s own smartphone, hence allowing us to integrate real-world apps and letting the user interact with them during the simulation.",Christian Eichhorn: Technical University of Munich; Martin Lurz: Technical University of Munich; David A. Plecher: Technical University; Sandro Weber: Technical University of Munich; Monika Wintergerst: Technical University of Munich; Birgit Kaiser: Technical University of Munich; Sophie Laura Holzmann: Chair of Nutritional Medicine; Christina Holzapfel: Technical University of Munich; Hans Hauner: Technical University of Munich; Kurt M. Gedrich: Technical University of Munich; Georg Groh: Technical University of Munich; Markus Böhm: Technical University of Munich; Helmut Krcmar: Technical University of Munich; Gudrun Klinker: TUM,
C2527,"DCGH: Dynamic Computer Generated Holography for Speckle-Free, High Fidelity 3D Displays",Vincent R Curtis,tmcurtis291@unc.edu,"Computer Generated Holography (CGH) is a promising technique for synthesizing 3D images. However, CGH displays that modulate coherent light with a static 2D pattern can only render a small subset of all the possible illumination patterns where speckle noise is omnipresent. Here, we introduce Dynamic CGH, a new holographic technique that modulates light both spatially and temporally with globally optimized patterns, enabling 3D light sculpting with many more degrees of control. Experimental results obtained with a high-speed Digital Micromirror Device (DMD) show that DCGH yields speckle-free 3D images with improved resolution and contrast, successfully addressing the shortcomings of single-frame holography.",Vincent R Curtis: University of North Carolina-Chapel Hill; Nicholas William Caira: University of North Carolina-Chapel Hill; Jiayi Xu: University of North Carolina-Chapel Hill; Asha Gowda Sata: University of North Carolina-Chapel Hill; Nicolas C Pegard: University of North Carolina at Chapel Hill,
C2528,Where are you? Influence of Redirected Walking on Audio-Visual Position Estimation of Co-Located Users,Lucie Kruse,kruse@informatik.uni-hamburg.de,"Two-user redirected walking (RDW) promises new possibilities for collaborative experiences in virtual reality (VR), but it also introduces challenges like the spatial de-synchronization emerging when one or more users are redirected in different ways. 
We analyzed the ability to estimate a co-located user's position, and assessed the feeling of representation consistency in an interactive game. Results show that a user's estimation of the other's position improves when their partner's virtual and physical position get closer together. Furthermore, larger redirection gains lead to a lower feeling of consistency, which also applies if only one person is redirected.",Lucie Kruse: Universität Hamburg; Eike Langbehn: University of Hamburg; Frank Steinicke: Universität Hamburg,
C2530,Story CreatAR: a Toolkit for Spatially-Adaptive Augmented Reality Storytelling,Abbey Singh,ab541393@dal.ca,"Headworn Augmented Reality (AR) and Virtual Reality (VR) displays are an exciting new medium for locative storytelling. Authors face challenges planning and testing the placement of story elements when the story is experienced in multiple locations or the environment is large or complex. We present Story CreatAR, the first locative AR/VR authoring tool that integrates spatial analysis techniques. Story CreatAR is designed to help authors think about, experiment with, and reflect upon spatial relationships between story elements, and between their story and the environment. We motivate and validate our design through developing different locative AR/VR stories with several authors.",Abbey Singh: Dalhousie; Ramanpreet Kaur: Dalhousie University; Peter Haltner: Dalhousie University; Matthew Peachey: Dalhousie University; Mar Gonzalez-Franco: Microsoft Research; Joseph Malloch: Dalhousie University; Derek Reilly: Dalhousie University,
C2532,Effective close-range accuracy comparison of Microsoft HoloLens Generation one and two using Vuforia ImageTargets,Jonas Simon Iven Rieder,jonas.s.i.rieder@gmail.com,"This paper analyzes the effective accuracy for close-range operations for the first and the second generation of Microsoft HoloLens in combination with Vuforia Image Targets in a black-box approach. The authors developed a method to benchmark and compare the applicability of these devices for tasks that demand a higher accuracy like composite manufacturing or medical surgery assistance. Furthermore, the method can be used for a broad variety of devices, establishing a platform for bench-marking and comparing these and future devices.",Jonas Simon Iven Rieder: TU Delft; Daniëlle Hilde van Tol: TU Delft; Doris Aschenbrenner: TU Delft,
C2537,Optimal time window for the integration of spatial audio-visual information in virtual environments,Ifat Yasin,i.yasin@ucl.ac.uk,"This study investigated audio-visual integration in a virtual environment. Two tasks were used, an auditory localization task and a detection task (judgement of audio-visual synchrony). The short-duration auditory stimuli (35-ms spatialized sound) and long-duration auditory stimuli (600-ms non-spatialized sound followed by 35 ms of spatialized sound) were presented between -60 and +60 degrees azimuth, with the visual stimulus presented synchronously/asynchronously with respect to the start of the auditory stimulus. Auditory localization errors and audio-visual synchrony detection reveal the effects of underlying neural mechanisms that can be harnessed to optimize audio-visual experiences in virtual environments.",Jiacheng Liu: University College London; Vit Drga: University College London; Ifat Yasin: University College London,
C2538,Comparing the Neuro-Physiological Effects of Cinematic Virtual Reality with 2D Monitors,Mr. Ruochen Cao,caory004@mymail.unisa.edu.au,"In this work, we explore if the immersion afforded by Virtual Reality can improve the cognitive integration of information in Cinematic Virtual Reality (CVR). We conducted a user study examining participants' cognitive activities when consuming visual information of emotional and emotionally neutral scenes in a non-CVR environment (i.e. a monitor) versus a CVR environment (i.e. a head-mounted display). Cortical response was recorded using electroencephalography. We found that participants had greater early visual attention with neutral emotions in CVR environments, and showed higher overall alpha power in CVR environments. The use of CVR did not significantly affect participants' recall performance.",Ruochen Cao: University of South Australia; Lena Zou-Williams: University of South Australia; Andrew Cunningham: University of South Australia; James A. Walsh: University of South Australia; Mark Kohler: University of Adelaide; Bruce H Thomas: University of South Australia,
C2541,VR System for the Restoration of Broken Cultural Artifacts on the Example of a Funerary Monument,Patrick Saalfeld,patrick@isg.cs.uni-magdeburg.de,"We present a VR system that supports the restoration of broken cultural artifacts. As a case study, we demonstrate this approach on a funerary monument.
Among the challenges of this monument are a large number of 415 fragments, missing pieces prevent full reconstruction and fragments vary strongly in size.
Our system offers a configurable self-arranging fragment wall, which supports the user to organize fragments and identify relevant ones. We implemented two sets of manipulation techniques for rough aligning and precise assembly.
The iterative development was accompanied by a restorer that reconstructed the monument within 14 sessions and 21 hours.",Patrick Saalfeld: Otto-von-Guericke University; Claudia Böttcher: Förderverein Dom zu Magdeburg e.V.; Fabian Klink: Department of Mechanical Engineering; Bernhard Preim: Otto-von-Guericke University,
C2547,Freehand Grasping: An Analysis of Grasping for Docking Tasks in Virtual Reality,Andreea Dalia Blaga,andreea.blaga@mail.bcu.ac.uk,"Natural interaction such as freehand grasping is still a significant challenge in VR due to the dexterous versatility of the human grasping actions. Currently, the design considerations for creating freehand grasping interactions in VR are drawn from the body of knowledge presented for real object grasping. While this may be suitable for some applications, recent work has shown that users grasp virtual objects differently than they grasp real objects, presenting an absence of knowledge on grasp patterns in VR. We present an elicitation study where participants grasp virtual objects categorised by shape in a mixed docking task. Our results are of value to be taken forward into parameterising grasp types for developing intuitive grasp models.",Andreea Dalia Blaga: Birmingham City University; Maite Frutos-Pascual: Birmingham City University; Chris Creed: Birmingham City University; Ian Williams: Birmingham City University,
C2578,Do we still need physical monitors? An evaluation of the usability of AR virtual monitors for productivity work,Leonardo Pavanatto,lpavanat@vt.edu,"Physical monitors require space, lack flexibility, and can become expensive and less portable in large setups. Virtual monitors can be subject to technological limitations such as lower resolution and field of view. We investigate the impacts of using virtual monitors on a current state-of-the-art augmented reality headset for conducting productivity work. We conducted a user study that compared physical monitors, virtual monitors, and a hybrid combination of both in terms of performance, accuracy, comfort, focus, preference, and confidence. Results show that virtual monitors are a feasible approach, albeit with inferior usability and performance, while hybrid was a middle ground.",Leonardo Pavanatto: Virginia Tech; Chris North: Virginia Tech; Doug Bowman: Virginia Tech; Richard Stoakley: Microsoft Corp.; Carmen Badea: Microsoft Corp.,
C2579,Evaluating the Potential of Glanceable AR Interfaces for Authentic Everyday Uses,Feiyu Lu,feiyulu@vt.edu,"In the near future, augmented reality (AR) glasses are envisioned to become the next-generation personal computing platform. However, it remains unclear how we could enable unobtrusive and easy information access in AR without distracting users, while being acceptable to use at the same time. To address this question, we implemented two prototypes based on the Glanceable AR paradigm. We conducted two separate studies to evaluate our designs. We found that users appreciated the Glanceable AR approach in authentic everyday use cases. They found it less distracting or intrusive than existing devices, and would like to use the interface on a daily basis if the form factor of the AR headset was more like eyeglasses.",Feiyu Lu: Virginia Tech; Doug Bowman: Virginia Tech,
C2582,Estimating Gaze From Head and Hand Pose and Scene Images for Open-Ended Exploration in VR Environments,Kara J Emery,karaemery@nevada.unr.edu,"Though previous research has shown coordination between non-eye signals and gaze, whether head, hand, and scene signals and their complete combination are useful for estimating gaze has not yet been quantified. To address this, we collected a dataset of head, hand, scene, and gaze signals as users explore open-ended virtual environments hosting a variety of potential actions. We show that gaze estimation models trained on signals from each individual sensor and their full combination outperform baseline gaze estimates across cross-validation methods. We conclude that these non-eye signals comprise useful information for estimating gaze that can complement traditional eye tracking methodologies.","Kara J Emery: The University of Nevada, Reno; Marina Zannoli: Facebook Reality Labs; Lei Xiao: Facebook Reality Labs; James Warren: Facebook Reality Labs; Sachin S Talathi: Facebook",
C2584,Personal Identifiability of User Tracking Data During VR Training,Alec G Moore,agm@knights.ucf.edu,"Recent research indicates that user tracking data from virtual reality (VR) experiences can be used to personally identify users at accuracies as high as 95 percent. However, these results indicating that non-verbal data should be understood as personally identifying data were based on observing 360-degree videos. In this paper, we present participant identification results based on a session of user tracking data from a VR training application, which show accuracies above 90 percent. While still highly accurate, this decrease indicates that the personal identifiability of user tracking data is likely dependent upon the nature of the underlying VR experience.",Alec G Moore: University of Central Florida; Ryan P. McMahan: University of Central Florida; Hailiang Dong: University of Texas at Dallas; Nicholas Ruozzi: University of Texas in Dallas,
C2586,The Importance of Sensory Feedback to Enhance Embodiment during Virtual Training of Myoelectric Prostheses Users,Dr. Edgard Afonso Lamounier Jr.,lamounier@ufu.br,"In this poster, we propose a system that uses immersive Virtual Reality (iVR) and EMG signal processing (muscle activity) to provide a training environment for amputees who are supposed to use a myoelectric prosthesis. We also investigate the efficiency of learning how to control a virtual prosthesis with and without sensory feedback. Our results show that virtual training can be greatly improved when proper tactile feedback is provided, especially for controlling myoelectric prostheses.","Reidner Santos Cavalcante: Universidade Federal de Uberlândia; Aya Gaballa: Qatar University; John Cabibihan: Qatar University; Alcimar Soares: Faculty of Electrical Engineering, Federal University of Uberlândia; Edgard Afonso Lamounier Jr.: Federal University of Uberlândia",
C2589,Evaluating Object Manipulation Interaction Techniques in Mixed Reality: Tangible User Interfaces and Gesture,Lila Bozgeyikli,lboz@email.arizona.edu,"Tangible user interfaces (TUIs) have been widely studied in computer, virtual reality and augmented reality systems. However, there have been few evaluations of TUIs in wearable mixed reality (MR). We evaluated three object manipulation techniques in wearable MR: (1) Space-multiplexed identical-formed TUI (physical cube); (2) Time-multiplexed TUI (tangible controller); (3) Hand gesture. The interaction techniques were compared with a user study with 42 participants. Results revealed that the tangible cube and the controller were comparative to each other while both being superior to the hand gesture in terms of user experience, performance, and presence.",Evren Bozgeyikli: University of Arizona; Lila Bozgeyikli: University of Arizona,
C2593,Revisiting Distance Perception with Scaled Embodied Cues in Social Virtual Reality,Zubin Choudhary,zubinchoudhary@knights.ucf.edu,"In this paper we investigate how the perception of avatar distance is changed based on two means for scaling embodied social cues: visual head scale and verbal volume scale. We conducted a human-subject study employing a mixed factorial design with two Social VR avatar representations (full-body, head-only) as a between factor as well as three visual head scales and three verbal volume scales (up-scaled, accurate, down-scaled) as within factors. We found that visual head scale had a significant effect on distance judgments, while verbal volume scales did not. We discuss the interactions between the factors and implications for Social VR.",Zubin Choudhary: University of Central Florida; Matt Gottsacker: University of Central Florida; Kangsoo Kim: University of Central Florida; Ryan Schubert: University of Central Florida; Jeanine Stefanucci: University of Utah; Gerd Bruder: University of Central Florida; Greg Welch: University of Central Florida,
C2596,The Effect of Feedback on Estimates of Reaching Ability in Virtual Reality,Jeanine Stefanucci,jeanine.stefanucci@psych.utah.edu,"We evaluated judgments of two action capabilities – reaching out and up – within a virtual environment (VE). We assessed whether feedback from reaching improved judgments and if recalibration from feedback differed across reaching behaviors. In feedback trials, participants viewed targets that were farther or closer than their actual reach, decided whether the target was reachable, and then reached out to the target to receive visual feedback. For both behaviors, reach was initially overestimated, and then adjustments decreased to become more accurate with feedback. This study establishes a straightforward methodology that can be used for calibration of actions in VEs.","Holly C Gagnon: University of Utah; Taren Rohovit: University of Utah; Hunter Finney: University of Utah; Yu Zhao: Vanderbilt University; John Franchak: University of California, Riverside; Jeanine Stefanucci: University of Utah; Sarah Creem-Regehr: University of Utah; Bobby Bodenheimer: Vanderbilt University",
C2598,Affordance Judgments in Mobile Augmented Reality with Cues,Yu Zhao,yu.zhao@vanderbilt.edu,"We investigated two judgments of action capabilities with virtual objects presented through smartphones: passing through an aperture and stepping over a gap. The results showed that users were conservative in their affordance judgments for the two actions, but that judgments became more accurate with training by AR cues. In the post-cue trials, passing through judgments improved; in contrast, stepping over judgments became more precise when the cue was present, but did not display the same generalization in the post-cue block of improved estimates.",Yu Zhao: Vanderbilt University; Jeanine Stefanucci: University of Utah; Sarah Creem-Regehr: University of Utah; Bobby Bodenheimer: Vanderbilt University,
C2602,A Rate-based Drone Control with Adaptive Origin Update in Telexistence,Hao Gao,tsgaohao@gmail.com,"A new form of telexistence is achieved by recording videos with a camera on an Uncrewed aerial vehicle (UAV) and playing the videos to a user via a head-mounted display (HMD). User studies demonstrate that comparing with other telexistence solutions and the widely used joystick-based solutions, our solution largely reduces the workload and saves time and moving distance for the user.",Di Zhang: Nanjing University of Posts and Telecommunications; Chi-Man Pun: University of Macau; Hao Gao: Nanjing University of Posts and Telecommunications; Feng Xu: Tsinghua University,
C2604,Temporal Availability of Ebbinghaus Illusions on Perceiving and Interacting with 3D Objects in a Contextual Virtual Environment,Amy Banic,abanic@cs.uwyo.edu,"Contextual illusions, such as the Ebbinghaus Illusion, can be potentially used to improve or hinder reach-to-grasp interaction in a virtual environment. It remains unknown how the sudden, or dynamic, change of surrounding features will impact the perception and then the action towards the object. We conducted a series of experiments to evaluate the effects of 3D Ebbinghaus illusion with dynamic surrounding features on the task of reaching to grasp a 3D object in an immersive virtual environment. An innovative 3D perceptual judgment task was implemented. The kinematics of reach-to-grasp task were we experimentally manipulated the visual gain and loss of the 3D contextual inducers, the participant’s virtual hand, and the 3D contextual object.",Russell Todd: University of Wyoming; Qin Zhu: University of Wyoming; Amy Banic: University of Wyoming,
C2609,LighterBody: RNN based Anticipated Virtual Body Makes You Feel Lighter,Shunichi Kasahara,kasahara@csl.sony.co.jp,"The virtual body representation had shown the potential of intervention into the sense of body. To investigate how the temporal shift of body representation affects the user’s kinetic sensation, we developed a system to anticipate body movement with RNN. We then conducted a user study to assess the effect with the anticipated body movement and the system baseline. Results revealed that the transition from the baseline to the anticipated body induced a lighter bodyweight feeling, and the opposite transition induced a heavier feeling. Our work enlightens the potential of interactive manipulation of the full-body kinetic sensation using virtual body representation.",Tatsuya Kure: SonyCSL; Shunichi Kasahara: Sony CSL,
C2622,Detecting the Point of Release of Virtual Projectiles in AR/VR,Carol O'Sullivan,carol.osullivan@scss.tcd.ie,"Our aim is to detect the point of release of a thrown virtual projectile in VR/AR. We capture the full-body motion of 18 participants throwing virtual projectiles and extract motion features, such as position, velocity, rotation and rotational velocity for arm joints. Frame-level binary classifiers that estimate the point of release are trained and evaluated using a metric that prioritizes detection timing to obtain an importance ranking of joints and motion features. We find that the wrist joint and the rotation motion feature are most accurate, which can guide the placement of simple motion tracking sensors for real-time throw detection.",Goksu Yamac: Trinity College Dublin; Niloy Mitra: University College London; Carol O'Sullivan: Trinity College Dublin,
C2627,Mid-Air Finger Sketching for Tree Modeling,Zhanglin Cheng,zl.cheng@siat.ac.cn,"We explore the use of mid-air finger 3D sketching in VR for tree modeling. We present a hybrid approach that integrates freehand 3D sketches with an automatic population of branch geometries. The user only needs to draw a few 3D strokes in mid-air to define the envelope of the foliage and main branches. Our algorithm then automatically generates a full 3D tree model based on these stroke inputs. We demonstrate the ease-of-use, efficiency, and flexibility in tree modeling and overall shape control. We perform user studies and show a variety of realistic tree models generated instantaneously from 3D finger sketching.","Fanxing Zhang: Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Zhihao Liu: Chinese Academy of Sciences; Zhanglin Cheng: Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Oliver Deussen: Chinese Academy of Sciences; Baoquan Chen: Peking University; Yunhai Wang: Shandong University",
C2628,Self-Avatars in Virtual Reality: A Study Protocol for Investigating the Impact of the Deliberateness of Choice and the Context-Match,Andrea Bartl,andrea.bartl@uni-wuerzburg.de,"The illusion of virtual body ownership (VBO) plays a critical role in virtual reality (VR). VR applications provide a broad design space which includes contextual aspects of the virtual surroundings as well as user-driven deliberate choices of their appearance in VR potentially influencing VBO and other well-known effects of VR. We propose a protocol for an experiment to investigate the influence of deliberateness and context-match on VBO and presence. In a first study, we found significant interactions with the environment. Based on our results we derive recommendations for future experiments.","Andrea Bartl: University of Würzburg, Department of Computer Science, HCI Group; Sungchul Jung: University of Canterbury; Peter Kullmann: University of Würzburg; Stephan Wenninger: TU Dortmund University; Jascha Achenbach: Bielefeld University; Erik Wolf: University of Würzburg, Department of Computer Science, HCI Group; Christian Schell: Department of Computer Science, HCI Group; Robert W. Lindeman: University of Canterbury; Mario Botsch: TU Dortmund University; Marc Erich Latoschik: Department of Computer Science, HCI Group",
C2639,Learning Acoustic Scattering Fields for Dynamic Interactive Sound Propagation,Zhenyu Tang,zhy@cs.umd.edu,"We present a novel hybrid sound propagation algorithm for interactive applications. Our approach is designed for dynamic scenes and uses a neural network-based learned scattered field representation along with ray tracing to generate specular, diffuse, diffraction, and occlusion effects efficiently. We use geometric deep learning to approximate the acoustic scattering field using spherical harmonics. We use a large 3D dataset for training, and compare its accuracy with the ground truth generated using an accurate wave-based solver. We demonstrate its interactive performance by generating plausible sound effects in dynamic scenes with diffraction and occlusion effects.",Zhenyu Tang: University of Maryland; Hsien-Yu Meng: University of Maryland; Dinesh Manocha: University of Maryland,
C2640,[NO FINAL TITLE PROVIDED. ORIGINAL TITLE: Test Submission 1],Test Author,test_author_vr21a@precisionconference.com,,,
C2642,[NO FINAL TITLE PROVIDED. ORIGINAL TITLE: Test Submission 3],Test Author,test_author_vr21a@precisionconference.com,,,
C2643,[NO FINAL TITLE PROVIDED. ORIGINAL TITLE: Test Submission 4],Test Author,test_author_vr21a@precisionconference.com,,,